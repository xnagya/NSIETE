{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __WanDB Experiment__\n",
    "This file connects _models.py_ and _trainer.py_ files and manages experiments created in wanDB. It also contains dataset reresentation as Dataset subclass (Lizard_dataset). Experiments are defined in file NN-z2 (main file).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:391: UserWarning: Overwriting pvt_v2_b0 in registry with pvtv2.pvt_v2_b0. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "c:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:401: UserWarning: Overwriting pvt_v2_b1 in registry with pvtv2.pvt_v2_b1. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "c:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:409: UserWarning: Overwriting pvt_v2_b2 in registry with pvtv2.pvt_v2_b2. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "c:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:417: UserWarning: Overwriting pvt_v2_b3 in registry with pvtv2.pvt_v2_b3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "c:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:425: UserWarning: Overwriting pvt_v2_b4 in registry with pvtv2.pvt_v2_b4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "c:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:434: UserWarning: Overwriting pvt_v2_b5 in registry with pvtv2.pvt_v2_b5. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n"
     ]
    }
   ],
   "source": [
    "import net_config as cfg\n",
    "from models import *\n",
    "from trainer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class\n",
    "This class is parsed to DataLoader in trainer.py \n",
    "\n",
    "Images are loaded to tensors __(dtype = float32)__ from argument 'path_images' </br>\n",
    "Labels are loaded to tensors __(dtype = int64)__ from argument 'path_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lizard_dataset(Dataset):\n",
    "    def __init__(self, path_images, path_labels):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.transform = T.ToPILImage()\n",
    "\n",
    "        self.class_colors = torch.FloatTensor([\n",
    "            [0, 0, 0]           #black\n",
    "            , [30, 144, 255]    #dodger blue\n",
    "            , [220, 20, 60]     #crimson\n",
    "            , [34, 139, 34]     #forest green\n",
    "            , [238, 130, 238]   #violet\n",
    "            , [255, 255, 0]     #yellow\n",
    "            , [211, 211, 211]   #gainsboro\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Load images and labels as tensors to cpu (moved to gpu during training)\n",
    "        self.images = torch.load(path_images, map_location=\"cpu\").type(torch.float32)\n",
    "        self.labels = torch.load(path_labels, map_location=\"cpu\").type(torch.int64)\n",
    "\n",
    "        img_count = self.images.size(dim=0)\n",
    "        num_channels = self.images.size(dim=1)\n",
    "        height = self.images.size(dim=2)\n",
    "        width = self.images.size(dim=3)\n",
    "\n",
    "        img_count2 = self.labels.size(dim=0)\n",
    "        height2 = self.labels.size(dim=1)\n",
    "        width2 = self.labels.size(dim=2)\n",
    "\n",
    "        assert img_count == img_count2, f\"Wrong IMAGE COUNT for dataset: images = {img_count} | labels = {img_count2}\"\n",
    "        assert height == height2, f\"Wrong image HEIGHT for dataset: images = {height} | labels = {height2}\"\n",
    "        assert width == width2, f\"Wrong image WIDTH for dataset: images = {width} | labels = {width2}\"\n",
    "        assert num_channels == 3, f\"Wrong image CHANNEL COUNT for dataset: images = {num_channels} | needed = 3\"\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.size(dim=0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx, :, :, :]\n",
    "        label = self.labels[idx, :, :]\n",
    "\n",
    "        return (image, label)\n",
    "    \n",
    "    def show_imgLabel(self, idx):\n",
    "        img_t, label_t = self.__getitem__(idx)\n",
    "\n",
    "        # Show image\n",
    "        image = self.transform(img_t)\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image)\n",
    "        plt.title(f'Original Image  with index = {idx}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        # show segmentation\n",
    "        converted_tensor = torch.nn.functional.embedding(label_t.type(torch.int64), self.class_colors).permute(2, 0, 1)\n",
    "        colormap = self.transform(converted_tensor)\n",
    "\n",
    "        # show segmentation\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(colormap)\n",
    "        plt.title('Segmentation Heatmap')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def show_tensorImg(self, t):\n",
    "        t = torch.squeeze(t)\n",
    "        img = self.transform(t)\n",
    "        plt.show(img)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wanDB run class\n",
    "\n",
    "This class executes training epochs by calling trainer functions. It also logs metrics and decides when the model params are saved (locally).\n",
    "This class contains: \n",
    "- Current wanDB run \n",
    "- Trainer\n",
    "- Save interval (every n-th epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wanDB_run: \n",
    "    def __init__(self, run_name, run_id, model: nn.Module, save_interval = None):\n",
    "        wandb.login()\n",
    "        \n",
    "        wandb.finish()\n",
    "        \n",
    "        self.run = wandb.init(\n",
    "        entity = cfg.project_entity, \n",
    "        project = cfg.project_name,     \n",
    "        name = run_name, \n",
    "        id = run_id\n",
    "        )\n",
    "\n",
    "        wandb.config = cfg.config_to_dict(cfg.config_Unet)\n",
    "\n",
    "        self.trainer = Trainer(model)\n",
    "        self.save_interval = save_interval\n",
    "        self.datasets_loaded = False\n",
    "        self.batch_count = 0\n",
    "\n",
    "        # Load best model\n",
    "        if (self.save_interval is not None) and os.path.isfile(cfg.model_path):\n",
    "            self.current_epoch = self.trainer.load_model()\n",
    "        else:\n",
    "            self.current_epoch = 0\n",
    "\n",
    "    def load_datasets(self, train_pathX, train_pathY, val_pathX, val_pathY, test_pathX, test_pathY):\n",
    "        trainData = Lizard_dataset(train_pathX, train_pathY)\n",
    "        valData = Lizard_dataset(val_pathX, val_pathY)\n",
    "        testData = Lizard_dataset(test_pathX, test_pathY)\n",
    "\n",
    "        self.trainer.load_dataset(trainData, valData, testData)\n",
    "        self.datasets_loaded = True\n",
    "    \n",
    "    def execute_training(self, epoch_count, log_batch = False):\n",
    "        assert self.datasets_loaded, \"Datasets are NOT loaded\"\n",
    "\n",
    "        for _ in range(epoch_count):\n",
    "            self.current_epoch += 1\n",
    "            print(f\"--Starting epoch {self.current_epoch}--\")\n",
    "\n",
    "            # Train model\n",
    "            self.trainer.train_model()\n",
    "            # Evaluate model\n",
    "            self.trainer.evaluate_model()\n",
    "\n",
    "            if log_batch:\n",
    "                for i in range(self.trainer.stats.batch_count()):\n",
    "                    self.batch_count += 1\n",
    "                    m = self.trainer.stats.batch_metrics(i)\n",
    "\n",
    "                    self.run.log({\"loss_train\": m.get(cfg.metric_name_Tloss), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"loss_val\": m.get(cfg.metric_name_Vloss), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"accuracy\": m.get(cfg.metric_name_acc), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"iou\": m.get(cfg.metric_name_iou), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"dice\": m.get(cfg.metric_name_dice), \"batch\": self.batch_count})\n",
    "\n",
    "            \n",
    "            else:\n",
    "                # Get metrics average\n",
    "                tl = self.trainer.stats.metric_average(cfg.metric_name_Tloss)\n",
    "                vl = self.trainer.stats.metric_average(cfg.metric_name_Vloss)\n",
    "                acc = self.trainer.stats.metric_average(cfg.metric_name_acc)\n",
    "                iou = self.trainer.stats.metric_average(cfg.metric_name_iou)\n",
    "                dice = self.trainer.stats.metric_average(cfg.metric_name_dice)\n",
    "\n",
    "                # Save metrics to wandb\n",
    "                self.run.log({\"loss_train\": tl, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"loss_val\": vl, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"accuracy\": acc, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"iou\": iou, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"dice\": dice, \"epoch\": self.current_epoch})\n",
    "\n",
    "            self.trainer.stats.clear()\n",
    "            gc.collect()\n",
    "\n",
    "            # Save best model\n",
    "            if (self.save_interval is not None) and (self.current_epoch % self.save_interval == 0):\n",
    "                self.trainer.save_model(self.current_epoch)\n",
    "\n",
    "            print(f\"--Ending epoch {self.current_epoch}--\")\n",
    "    \n",
    "    def stop_run(self):\n",
    "        self.run.finish()\n",
    "        del self.trainer\n",
    "        self.datasets_loaded = False\n",
    "\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This U-Net skips connections using concatenation.\n",
      "torch.Size([14, 3, 500, 500])\n",
      "torch.Size([14, 7, 500, 500])\n",
      "torch.Size([14, 500, 500])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "d = cfg.config_to_dict(cfg.config_Unet)\n",
    "\n",
    "net = U_Net(3, cfg.num_of_classes, d)\n",
    "#output_shapes(net, 500, 500)\n",
    "\n",
    "t = torch.rand(14, 3, 500, 500)\n",
    "print(t.shape)\n",
    "t = net(t)\n",
    "print(t.shape)\n",
    "\n",
    "classes = torch.argmax(t, dim = 1)\n",
    "print(classes.shape)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
