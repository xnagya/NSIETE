{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:386: UserWarning: Overwriting pvt_v2_b0 in registry with pvtv2.pvt_v2_b0. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "C:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:396: UserWarning: Overwriting pvt_v2_b1 in registry with pvtv2.pvt_v2_b1. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "C:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:404: UserWarning: Overwriting pvt_v2_b2 in registry with pvtv2.pvt_v2_b2. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "C:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:412: UserWarning: Overwriting pvt_v2_b3 in registry with pvtv2.pvt_v2_b3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "C:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:420: UserWarning: Overwriting pvt_v2_b4 in registry with pvtv2.pvt_v2_b4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "C:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\pvtv2.py:429: UserWarning: Overwriting pvt_v2_b5 in registry with pvtv2.pvt_v2_b5. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[2, 2, 2, 2],\n",
      "        [2, 2, 2, 2]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import os.path\n",
    "\n",
    "import net_config as cfg\n",
    "%run models.ipynb\n",
    "%run trainer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lizard_dataset(Dataset):\n",
    "    def __init__(self, path_images, path_labels):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.transform = T.ToPILImage()\n",
    "\n",
    "        self.class_colors = torch.FloatTensor([\n",
    "            [0, 0, 0]           #black\n",
    "            , [30, 144, 255]    #dodger blue\n",
    "            , [220, 20, 60]     #crimson\n",
    "            , [34, 139, 34]     #forest green\n",
    "            , [238, 130, 238]   #violet\n",
    "            , [255, 255, 0]     #yellow\n",
    "            , [211, 211, 211]   #gainsboro\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Load images and labels as tensors to cpu (moved to gpu during training)\n",
    "        self.images = torch.load(path_images, map_location=\"cpu\").type(torch.float32)\n",
    "        self.labels = torch.load(path_labels, map_location=\"cpu\").type(torch.int64)\n",
    "\n",
    "        #print(self.images.dtype)\n",
    "        #print(self.labels.dtype)\n",
    "\n",
    "        img_count = self.images.size(dim=0)\n",
    "        num_channels = self.images.size(dim=1)\n",
    "        height = self.images.size(dim=2)\n",
    "        width = self.images.size(dim=3)\n",
    "\n",
    "        img_count2 = self.labels.size(dim=0)\n",
    "        height2 = self.labels.size(dim=1)\n",
    "        width2 = self.labels.size(dim=2)\n",
    "\n",
    "        assert img_count == img_count2, f\"Wrong IMAGE COUNT for dataset: images = {img_count} | labels = {img_count2}\"\n",
    "        assert height == height2, f\"Wrong image HEIGHT for dataset: images = {height} | labels = {height2}\"\n",
    "        assert width == width2, f\"Wrong image WIDTH for dataset: images = {width} | labels = {width2}\"\n",
    "        assert num_channels == 3, f\"Wrong image CHANNEL COUNT for dataset: images = {num_channels} | needed = 3\"\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.size(dim=0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx, :, :, :]\n",
    "        label = self.labels[idx, :, :]\n",
    "        #image = torch.unsqueeze(image, dim= 0)\n",
    "        #label = torch.unsqueeze(label, dim= 0)\n",
    "\n",
    "        return (image, label)\n",
    "    \n",
    "    def show_imgLabel(self, idx):\n",
    "        img_t, label_t = self.__getitem__(idx)\n",
    "\n",
    "        # Show image\n",
    "        image = self.transform(img_t)\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image)\n",
    "        plt.title(f'Original Image  with index = {idx}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        # show segmentation\n",
    "        converted_tensor = torch.nn.functional.embedding(label_t.type(torch.int64), self.class_colors).permute(2, 0, 1)\n",
    "        colormap = self.transform(converted_tensor)\n",
    "\n",
    "        # show segmentation\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(colormap)\n",
    "        plt.title('Segmentation Heatmap')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def show_tensorImg(self, t):\n",
    "        t = torch.squeeze(t)\n",
    "        img = self.transform(t)\n",
    "        plt.show(img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wanDB_run: \n",
    "    def __init__(self, run_name, run_id, model: nn.Module, save_interval = None):\n",
    "        wandb.login()\n",
    "        assert wandb.run is None, \"wanDB has another run currently active\"\n",
    "        \n",
    "        self.run = wandb.init(\n",
    "        entity = cfg.project_entity, \n",
    "        project = cfg.project_name,     \n",
    "        name = run_name, \n",
    "        id = run_id\n",
    "        )\n",
    "\n",
    "        wandb.config = cfg.config_to_dict(cfg.config_Unet)\n",
    "\n",
    "        self.trainer = Trainer(model)\n",
    "        self.save_interval = save_interval\n",
    "        self.datasets_loaded = False\n",
    "\n",
    "        # Load best model\n",
    "        if (self.save_interval is not None) and os.path.isfile(cfg.model_path):\n",
    "            self.current_epoch = self.trainer.load_model()\n",
    "        else:\n",
    "            self.current_epoch = 0\n",
    "\n",
    "    def load_datasets(self, train_pathX, train_pathY, val_pathX, val_pathY, test_pathX, test_pathY):\n",
    "        trainData = Lizard_dataset(train_pathX, train_pathY)\n",
    "        valData = Lizard_dataset(val_pathX, val_pathY)\n",
    "        testData = Lizard_dataset(test_pathX, test_pathY)\n",
    "\n",
    "        self.trainer.load_dataset(trainData, valData, testData)\n",
    "        self.datasets_loaded = True\n",
    "    \n",
    "    def execute_training(self, epoch_count):\n",
    "        assert self.datasets_loaded, \"Datasets are NOT loaded\"\n",
    "\n",
    "        for _ in range(epoch_count):\n",
    "            self.current_epoch += 1\n",
    "            print(f\"--Starting epoch {self.current_epoch}--\")\n",
    "\n",
    "            # Train model\n",
    "            self.trainer.train_model()\n",
    "            # Evaluate model\n",
    "            self.trainer.evaluate_model()\n",
    "\n",
    "            # Get metrics\n",
    "            tl = self.trainer.stats.metric_average(cfg.metric_name_Tloss)\n",
    "            vl = self.trainer.stats.metric_average(cfg.metric_name_Vloss)\n",
    "            acc = self.trainer.stats.metric_average(cfg.metric_name_acc)\n",
    "            iou = self.trainer.stats.metric_average(cfg.metric_name_IoU)\n",
    "            dice = self.trainer.stats.metric_average(cfg.metric_name_dice)\n",
    "\n",
    "            # Save metrics to wandb\n",
    "            self.run.log({\"loss_train\": tl, \"epoch\": self.current_epoch})\n",
    "            self.run.log({\"loss_val\": vl, \"epoch\": self.current_epoch})\n",
    "            self.run.log({\"accuracy\": acc, \"epoch\": self.current_epoch})\n",
    "            self.run.log({\"iou\": iou, \"epoch\": self.current_epoch})\n",
    "            self.run.log({\"dice\": dice, \"epoch\": self.current_epoch})\n",
    "\n",
    "            # Save best model\n",
    "            if (self.save_interval is not None) and (self.current_epoch % self.save_interval == 0):\n",
    "                self.trainer.save_model(self.current_epoch)\n",
    "\n",
    "            print(f\"--Ending epoch {self.current_epoch}--\")\n",
    "    \n",
    "    def stop_run(self):\n",
    "        self.run.finish()\n",
    "        del self.trainer\n",
    "        self.datasets_loaded = False\n",
    "\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"NN\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatus13579\u001b[0m (\u001b[33mmteam0\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "%env \"WANDB_NOTEBOOK_NAME\" \"NN\"\n",
    "wandb.login()\n",
    "wandb.finish()\n",
    "\n",
    "save_interval = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatus13579\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\matul\\Desktop\\NSIETE\\zadanie2\\wandb\\run-20240409_161541-2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matus13579/NN-z2/runs/2' target=\"_blank\">testuv2</a></strong> to <a href='https://wandb.ai/matus13579/NN-z2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matus13579/NN-z2' target=\"_blank\">https://wandb.ai/matus13579/NN-z2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matus13579/NN-z2/runs/2' target=\"_blank\">https://wandb.ai/matus13579/NN-z2/runs/2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device for training\n"
     ]
    }
   ],
   "source": [
    "netv2 = UNetV2(cfg.num_of_classes, cfg.config_to_dict(cfg.config_Unet))\n",
    "\n",
    "myrun = wanDB_run(\"testuv2\", \"2\", netv2, 3)\n",
    "\n",
    "myrun.load_datasets(\n",
    "    cfg.data_dir + \"X_train.pt\"\n",
    "    , cfg.data_dir + \"y_train.pt\" \n",
    "    , cfg.data_dir + \"X_val.pt\"\n",
    "    , cfg.data_dir + \"y_val.pt\"\n",
    "    , cfg.data_dir + \"X_test.pt\"\n",
    "    , cfg.data_dir + \"y_test.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Starting epoch 1--\n",
      "torch.Size([4, 64, 125, 125])\n",
      "torch.Size([4, 128, 63, 63])\n",
      "torch.Size([4, 320, 32, 32])\n",
      "torch.Size([4, 512, 16, 16])\n",
      "------\n",
      "torch.Size([4, 32, 125, 125])\n",
      "torch.Size([4, 32, 63, 63])\n",
      "torch.Size([4, 32, 32, 32])\n",
      "torch.Size([4, 32, 16, 16])\n",
      "------\n",
      "torch.Size([4, 32, 16, 16])\n",
      "torch.Size([4, 32, 32, 32])\n",
      "torch.Size([4, 32, 63, 63])\n",
      "torch.Size([4, 32, 125, 125])\n",
      "------\n",
      "torch.Size([4, 32, 32, 32])\n",
      "torch.Size([4, 32, 32, 32])\n",
      "torch.Size([4, 7, 32, 32])\n",
      "torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 32, 63, 63])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (63) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m myrun\u001b[38;5;241m.\u001b[39mexecute_training(\u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 41\u001b[0m, in \u001b[0;36mwanDB_run.execute_training\u001b[1;34m(self, epoch_count)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--Starting epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain_model()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mevaluate_model()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30848\\3308846894.py:84\u001b[0m, in \u001b[0;36mTrainer.train_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data:\n\u001b[0;32m     82\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 84\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_pass(x, y)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# Save batch loss\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mupdate(cfg\u001b[38;5;241m.\u001b[39mmetric_name_Tloss, loss)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30848\\3308846894.py:66\u001b[0m, in \u001b[0;36mTrainer.forward_pass\u001b[1;34m(self, input, ground_truth)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_pass\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, ground_truth):\n\u001b[1;32m---> 66\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m     67\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(prediction, ground_truth)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30848\\2085429753.py:193\u001b[0m, in \u001b[0;36mUNetV2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28mprint\u001b[39m(f21\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 193\u001b[0m y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m f21\n\u001b[0;32m    194\u001b[0m seg_outs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseg_outs[\u001b[38;5;241m2\u001b[39m](y))\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28mprint\u001b[39m(seg_outs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (63) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "myrun.execute_training(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myrun.stop_run()\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
