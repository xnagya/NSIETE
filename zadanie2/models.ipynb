{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchvision import models\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Network\n",
    "num_classes = Number of classes expecteed from output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_layer(channels_in, channels_out, kernel_size, padding, stride, dilation):\n",
    "    layer = nn.ModuleList()\n",
    "\n",
    "    conv2d = nn.Conv2d(\n",
    "        in_channels = channels_in, \n",
    "        out_channels = channels_out, \n",
    "        kernel_size = kernel_size, \n",
    "        stride = stride, \n",
    "        padding = padding, \n",
    "        dilation = dilation\n",
    "    )\n",
    "    torch.nn.init.kaiming_normal_(conv2d.weight)\n",
    "    \n",
    "    layer.append(conv2d)\n",
    "    layer.append(nn.ReLU())\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Block(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, params: dict):\n",
    "        super().__init__()\n",
    "\n",
    "        # Config parameters\n",
    "        try:\n",
    "            block_width = params['block_width']\n",
    "            kernel_size = params['kernel_size']\n",
    "            padding = params['padding']\n",
    "            stride = params['stride']\n",
    "            dilation = params['dilation']\n",
    "            pool_type = params['pool_type']\n",
    "            pool_size = params['pool_kernel_size']\n",
    "        except KeyError as e:\n",
    "            raise Exception(f'Parameter \"{e.args[0]}\" NOT found!')\n",
    "        \n",
    "        # Add first Conv2D layer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.extend(conv2d_layer(channels_in, channels_out, kernel_size, padding, stride, dilation))\n",
    "\n",
    "        # Add other Conv2D layers\n",
    "        for _ in range(block_width - 1):\n",
    "            self.layers.extend(conv2d_layer(channels_out, channels_out, kernel_size, padding, stride, dilation))\n",
    "\n",
    "        # Add pooling layer\n",
    "        match pool_type:\n",
    "            case 'max':\n",
    "                self.pooling = nn.MaxPool2d(kernel_size=pool_size, stride=pool_size)\n",
    "            case 'avg':\n",
    "                self.pooling = nn.AvgPool2d(kernel_size=pool_size, stride=pool_size)\n",
    "\n",
    "\n",
    "    def forward_noSkip(self, x):\n",
    "        # Convolution\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Pooling\n",
    "        pooled = self.pooling(x)\n",
    "        \n",
    "        return pooled\n",
    "    \n",
    "    def forward_skip(self, x):\n",
    "        # Convolution\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Pooling\n",
    "        pooled = self.pooling(x)\n",
    "\n",
    "        return (pooled, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_Block(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, padding_t, params: dict):\n",
    "        super().__init__()\n",
    "\n",
    "        # Config parameters\n",
    "        try:\n",
    "            block_width = params['block_width']\n",
    "            kernel_size = params['kernel_size']\n",
    "            padding = params['padding']\n",
    "            stride = params['stride']\n",
    "            dilation = params['dilation']\n",
    "            pool_size = params['pool_kernel_size']\n",
    "            skip_features = params['skip_features']\n",
    "        except KeyError as e:\n",
    "            raise Exception(f'Parameter \"{e.args[0]}\" NOT found!')\n",
    "\n",
    "        # Add transpose convolution\n",
    "        channel_out_convT = math.floor(channels_in / 2)\n",
    "\n",
    "        self.convT = nn.ConvTranspose2d (\n",
    "            in_channels = channels_in, \n",
    "            out_channels = channel_out_convT, \n",
    "            kernel_size = pool_size, \n",
    "            stride = pool_size, \n",
    "            output_padding = padding_t\n",
    "        )\n",
    "        torch.nn.init.kaiming_normal_(self.convT)\n",
    "        \n",
    "        match skip_features:\n",
    "            case \"none\":\n",
    "                channels_in = channel_out_convT\n",
    "                pass\n",
    "            case \"concat\":\n",
    "                # Half of channels are from convT, other half from enc features\n",
    "                # channels_in = 2 * channel_out_convT\n",
    "                pass\n",
    "            case \"sdi\":\n",
    "                pass\n",
    "\n",
    "        # Add first Conv2D layer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.extend(conv2d_layer(channels_in, channels_out, kernel_size, padding, stride, dilation))\n",
    "\n",
    "        # Add other Conv2D layers\n",
    "        for _ in range(block_width - 1):\n",
    "            self.layers.extend(conv2d_layer(channels_out, channels_out, kernel_size, padding, stride, dilation))\n",
    "\n",
    "    def forward_noSkip(self, x):\n",
    "        # Transposed convolution\n",
    "        x = self.convT(x)\n",
    "\n",
    "        # Convolution\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_skip(self, x, enc_feature):\n",
    "        # Transposed convolution\n",
    "        x = self.convT(x)\n",
    "\n",
    "        # Crop feature image \n",
    "        # w = x.size(-1)\n",
    "        # diff = math.floor((enc_feature.size(-1) - w) / 2)\n",
    "        # enc_features = enc_features[:, :, diff:diff+w , diff:diff+w]\n",
    "\n",
    "        print(x.size())   \n",
    "        print(enc_feature.size())\n",
    "        \n",
    "        # Copy features\n",
    "        x = torch.cat([enc_feature, x], dim = 1)\n",
    "\n",
    "        # Convolution\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_Net(nn.Module):\n",
    "    def __init__(self, channels_in, num_classes, params: dict):\n",
    "        super().__init__()\n",
    "\n",
    "        torch.set_default_dtype(torch.float32)\n",
    "\n",
    "        # Config parameters\n",
    "        try:\n",
    "            channel_mul = params['channel_mul']\n",
    "            depth = params['network_depth']\n",
    "            channels_out = params['channels_out_init']\n",
    "            padding_convT = deepcopy(params['padding_convT'])\n",
    "            self.skip_features = params['skip_features']\n",
    "            if (len(padding_convT) != depth):\n",
    "                raise Exception(f\"Padding of Transposed convolution has length {len(padding_convT)}, but should be {depth}!\")\n",
    "            \n",
    "        except KeyError as e:\n",
    "            raise Exception(f'Parameter \"{e.args[0]}\" NOT found!')\n",
    "        \n",
    "        # Create encoder\n",
    "        self.encoders = nn.ModuleList()\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.encoders.append(Encoder_Block(channels_in, channels_out, params))\n",
    "            channels_in = channels_out\n",
    "            channels_out = math.floor(channels_out * channel_mul)\n",
    "\n",
    "        # Create bridge as Conv2D layer\n",
    "        last_encoder = Encoder_Block(channels_in, channels_out, params)\n",
    "        self.bridge = last_encoder.layers[0]\n",
    "\n",
    "        channels_in = channels_out\n",
    "        channels_out = math.floor(channels_in / channel_mul)\n",
    "\n",
    "        # Create decoder\n",
    "        self.decoders = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(depth) :\n",
    "            paddingT = padding_convT.pop(0)\n",
    "            self.decoders.append(Decoder_Block(channels_in, channels_out, paddingT, params))\n",
    "            channels_in = channels_out\n",
    "            channels_out = math.floor(channels_out / channel_mul)\n",
    "\n",
    "        # Create output layer (1x1 convolution, return logits)\n",
    "        self.output_layer = nn.Conv2d(\n",
    "            in_channels = channels_in, \n",
    "            out_channels = num_classes, \n",
    "            kernel_size = 1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        match self.skip_features:\n",
    "            # No skipping\n",
    "            case \"none\":\n",
    "                print(\"This U-Net does NOT skip any connections!\")\n",
    "                # Encoding\n",
    "                for enc in self.encoders:\n",
    "                    x = enc.forward_noSkip(x)\n",
    "\n",
    "                # Bridge between encoder and decoder\n",
    "                x = self.bridge(x)\n",
    "\n",
    "                # Decoding\n",
    "                for dec in self.decoders:\n",
    "                    x = dec.forward_noSkip(x)\n",
    "\n",
    "            # Cat tensors => features + pooled output\n",
    "            case \"concat\":\n",
    "                print(\"This U-Net skips connections using concatenation!\")\n",
    "                # Features created during enconding\n",
    "                features = []\n",
    "\n",
    "                # Encoding\n",
    "                for enc in self.encoders:\n",
    "                    x, enc_feature = enc.forward_skip(x)\n",
    "                    features.append(enc_feature)\n",
    "\n",
    "                # Bridge between encoder and decoder\n",
    "                x = self.bridge(x)\n",
    "\n",
    "                # Decoding\n",
    "                for dec in self.decoders:\n",
    "                    enc_output = features.pop()\n",
    "                    x = dec.forward_skip(x, enc_output)\n",
    "\n",
    "            case \"sdi\":\n",
    "                pass\n",
    "    \n",
    "\n",
    "        # Output as logits\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_output_shape(height, width, conv2d: nn.Module):\n",
    "    height = ((height + (2 * conv2d.padding[0]) - (conv2d.dilation[0] * (conv2d.kernel_size[0] - 1)) - 1) / conv2d.stride[0]) + 1\n",
    "    height = math.floor(height)\n",
    "    \n",
    "    width = ((width + (2 * conv2d.padding[1]) - (conv2d.dilation[1] * (conv2d.kernel_size[1] - 1)) - 1) / conv2d.stride[1]) + 1\n",
    "    width = math.floor(width)\n",
    "\n",
    "    return (height, width, conv2d.out_channels)\n",
    "\n",
    "def pool_output_shape(height, width, conv2d: nn.Module):\n",
    "    height = ((height + (2 * conv2d.padding) - (conv2d.dilation * (conv2d.kernel_size - 1)) - 1) / conv2d.stride) + 1\n",
    "    height = math.floor(height)\n",
    "    \n",
    "    width = ((width + (2 * conv2d.padding) - (conv2d.dilation * (conv2d.kernel_size - 1)) - 1) / conv2d.stride) + 1\n",
    "    width = math.floor(width)\n",
    "\n",
    "    return (height, width)\n",
    "\n",
    "def convT_output_shape(height, width, convT: nn.Module):\n",
    "    height = (height - 1) * convT.stride[0] - (2 * convT.padding[0]) + (convT.dilation[0] * (convT.kernel_size[0] - 1)) + convT.output_padding[0] + 1\n",
    "    \n",
    "    width = (width - 1) * convT.stride[1] - (2 * convT.padding[1]) + (convT.dilation[1] * (convT.kernel_size[1] - 1)) + convT.output_padding[1] + 1\n",
    "    \n",
    "    return (height, width, convT.out_channels)\n",
    "\n",
    "\n",
    "def output_shapes(net : U_Net, height, width):\n",
    "    h = height\n",
    "    w = width\n",
    "    depth = len(net.encoders) + 1\n",
    "\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(f\"CNN with depth = {depth}\")\n",
    "    print(\"----------------------------------------------\")\n",
    "\n",
    "    i = 1\n",
    "    for enc in net.encoders:\n",
    "        print(f\"||Layer {i} - encoders||\")\n",
    "\n",
    "        for l in enc.layers:\n",
    "            if not isinstance(l, nn.ReLU):\n",
    "                (h,w,c) = conv2d_output_shape(h, w, l)\n",
    "                print (f\"Conv2D -- H = {h} | W = {w} | C = {c}\")\n",
    "\n",
    "        (h,w) = pool_output_shape(h, w, enc.pooling)\n",
    "        print (f\"Pooling -- H = {h} | W = {w} | C = {c}\") \n",
    "\n",
    "        print()\n",
    "        i += 1\n",
    "            \n",
    "    print(f\"||Layer {i} - bridge||\")\n",
    "    (h,w,c) = conv2d_output_shape(h, w, net.bridge)\n",
    "    print (f\"H = {h} | W = {w} | C = {c}\")\n",
    "    print(\"----------------------------------------------\")\n",
    "\n",
    "    for dec in net.decoders:\n",
    "        print(f\"||Layer {i} - decoders||\")\n",
    "\n",
    "        (h,w,c) = convT_output_shape(h, w, dec.convT)\n",
    "        print (f\"Transpose -- H = {h} | W = {w} | C = {c}\")   \n",
    "\n",
    "        for l in dec.layers:\n",
    "            if not isinstance(l, nn.ReLU):\n",
    "                (h,w,c) = conv2d_output_shape(h, w, l)\n",
    "                print (f\"Conv2D -- H = {h} | W = {w} | C = {c}\")   \n",
    "\n",
    "        print()\n",
    "        i -= 1\n",
    "\n",
    "\n",
    "    print(f\"||Layer {i} - output||\")\n",
    "    (h,w,c) = conv2d_output_shape(h, w, net.output_layer)\n",
    "    print (f\"H = {h} | W = {w} | C = {c}\")\n",
    "    print(\"----------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
