{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statistics:\n",
    "    def __init__(self):\n",
    "        self.metrics = dict()\n",
    "\n",
    "    def update(self, metric_name, new_value):\n",
    "        if metric_name in self.metrics:\n",
    "            values = self.metrics[metric_name]\n",
    "            values.append(new_value)\n",
    "\n",
    "        else:\n",
    "            values = [new_value]\n",
    "            self.metrics.update({metric_name : values})\n",
    "\n",
    "    def get_metric(self, metric_name):\n",
    "        return self.metrics.get(metric_name)\n",
    "    \n",
    "    def epoch_count(self, metric_name = None):\n",
    "        # MAX number of epoch in metrics\n",
    "        if metric_name is None:\n",
    "            max = 0\n",
    "            for val in self.metrics.values():\n",
    "                if len(val) > max:\n",
    "                    max = len(val)\n",
    "\n",
    "            return max \n",
    "\n",
    "        # Epoch count for metric name\n",
    "        else:\n",
    "            if metric_name in self.metrics:\n",
    "                return len(self.metrics[metric_name])\n",
    "            else: \n",
    "                return 0\n",
    "     \n",
    "    # First epoch is 0\n",
    "    def epoch_metrics(self, epoch_num):\n",
    "        result = dict()\n",
    "        \n",
    "        for metric_name, values in self.metrics.items():\n",
    "            if (epoch_num >= 0) and (epoch_num < len(values)):\n",
    "                metric_val = values[epoch_num]\n",
    "                result.update({metric_name : metric_val})\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def metric_average(self, metric_name):\n",
    "        if metric_name in self.metrics:\n",
    "            values = self.metrics[metric_name]\n",
    "            return float(sum(values) / len(values))\n",
    "        \n",
    "        else: \n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(prediction, mask):\n",
    "    with torch.no_grad():\n",
    "        pixel_count = float(mask.numel())\n",
    "\n",
    "        prediction = torch.argmax(torch.softmax(prediction, dim=1), dim=1)\n",
    "        correct = torch.eq(prediction, mask).int()\n",
    "\n",
    "        accuracy = float(correct.sum()) / pixel_count\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def IoU(prediction, mask):\n",
    "    pass\n",
    "\n",
    "def dice(prediction, mask):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, config: Namespace, model: nn.Module):\n",
    "\n",
    "        # Config and its parameters\n",
    "        try:\n",
    "            lrate = config.learning_rate\n",
    "            (beta1, beta2) = config.betas\n",
    "            wd = config.weight_decay\n",
    "            self.batch_size = config.batch_size\n",
    "        except AttributeError as e:\n",
    "            raise Exception(f'Parameter \"{e.name}\" NOT found!')\n",
    "\n",
    "        # Select GPU device\n",
    "        self.device = (\n",
    "            \"cuda\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "        print(f\"Using {self.device} device for training\")\n",
    "\n",
    "        # Move model to available device\n",
    "        self.network = model.to(self.device)\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lrate, betas=(beta1, beta2), weight_decay=wd)\n",
    "\n",
    "        # Loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Statistics (metrics for each epoch)\n",
    "        self.stats = Statistics()\n",
    "\n",
    "    # Create Data Loaders\n",
    "    def load_dataset(self, train_data, val_data, test_data):\n",
    "        self.train_data = DataLoader(train_data, batch_size= self.batch_size, shuffle= True)\n",
    "        self.val_data = DataLoader(val_data, batch_size= self.batch_size, shuffle= True)\n",
    "        self.test_data = DataLoader(test_data, batch_size= self.batch_size, shuffle= False)\n",
    "\n",
    "    # Forward Pass - create prediction and return its error (loss)\n",
    "    def forward_pass(self, input, ground_truth):\n",
    "        prediction = self.model(input)\n",
    "        loss = self.loss_fn(prediction, ground_truth)\n",
    "        return loss\n",
    "    \n",
    "    # Backward Pass - update parameters (weights, bias)\n",
    "    def backward_pass(self, loss_value):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def train(self, logger = None):\n",
    "        self.model.train()\n",
    "\n",
    "        # Train model on each dataset batch (train_data)\n",
    "        for x, y in self.train_data:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "\n",
    "            loss = self.forward_pass(x, y)\n",
    "\n",
    "            # Save batch loss\n",
    "            self.stats.update(\"train_loss\", loss)\n",
    "\n",
    "            self.backward_pass(loss)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.val_data:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "\n",
    "                loss = self.forward_pass(x, y)\n",
    "\n",
    "                # Save batch loss\n",
    "                self.stats.update(\"val_loss\", loss)\n",
    "\n",
    "    def test_model(self):\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.test_data:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "\n",
    "                pred = self.model(x)\n",
    "\n",
    "                # TODO - add metrics\n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_images = tensor_images.pt\n",
    "# path_labels = tensor_labels.pt\n",
    "\n",
    "class Lizard_dataset(Dataset):\n",
    "    def __init__(self, path_images, path_labels):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Load images and labels as tensors\n",
    "        images_t = torch.load(path_images)\n",
    "        labels_t = torch.load(path_labels)\n",
    "\n",
    "        img_count = images_t.size(dim=0)\n",
    "        num_channels = images_t.size(dim=1)\n",
    "        height = images_t.size(dim=2)\n",
    "        width = images_t.size(dim=3)\n",
    "\n",
    "        if ( img_count != labels_t.size(dim=0) or \n",
    "            num_channels != labels_t.size(dim=1) or \n",
    "            height != labels_t.size(dim=2) or \n",
    "            width != labels_t.size(dim=3)):\n",
    "\n",
    "            print(\"Wrong tensor shapes!\")\n",
    "            print (f\"- Images tensor shape : '{images_t.shape}'\")\n",
    "            print (f\"- Labels tensor shape : '{labels_t.shape}'\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.images[idx], self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.uint8\n",
      "tensor([[[[208, 219, 175,  ..., 201, 221, 231],\n",
      "          [214, 226, 167,  ..., 195, 215, 213],\n",
      "          [186, 197, 154,  ..., 186, 192, 198],\n",
      "          ...,\n",
      "          [200, 192, 204,  ..., 207, 221, 234],\n",
      "          [199, 202, 210,  ..., 234, 246, 245],\n",
      "          [209, 209, 212,  ..., 252, 245, 223]],\n",
      "\n",
      "         [[183, 195, 149,  ..., 145, 170, 180],\n",
      "          [189, 202, 141,  ..., 144, 166, 165],\n",
      "          [160, 172, 128,  ..., 141, 149, 157],\n",
      "          ...,\n",
      "          [155, 146, 152,  ..., 185, 201, 215],\n",
      "          [152, 154, 159,  ..., 216, 229, 228],\n",
      "          [168, 169, 172,  ..., 238, 230, 207]],\n",
      "\n",
      "         [[234, 239, 207,  ..., 198, 222, 234],\n",
      "          [244, 246, 201,  ..., 199, 222, 223],\n",
      "          [226, 231, 194,  ..., 205, 211, 216],\n",
      "          ...,\n",
      "          [219, 209, 215,  ..., 222, 233, 244],\n",
      "          [212, 214, 219,  ..., 243, 252, 252],\n",
      "          [217, 216, 219,  ..., 254, 252, 236]]],\n",
      "\n",
      "\n",
      "        [[[202, 203, 197,  ..., 237, 240, 232],\n",
      "          [194, 197, 191,  ..., 235, 241, 234],\n",
      "          [199, 192, 208,  ..., 218, 225, 235],\n",
      "          ...,\n",
      "          [159, 163, 197,  ..., 201, 203, 215],\n",
      "          [146, 142, 152,  ..., 199, 199, 227],\n",
      "          [167, 155, 139,  ..., 213, 205, 213]],\n",
      "\n",
      "         [[165, 167, 159,  ..., 228, 231, 224],\n",
      "          [159, 161, 155,  ..., 226, 232, 224],\n",
      "          [163, 156, 171,  ..., 209, 216, 226],\n",
      "          ...,\n",
      "          [125, 132, 156,  ..., 162, 165, 178],\n",
      "          [112, 108, 112,  ..., 160, 161, 191],\n",
      "          [131, 117,  99,  ..., 175, 168, 178]],\n",
      "\n",
      "         [[231, 234, 227,  ..., 242, 244, 237],\n",
      "          [207, 217, 214,  ..., 240, 246, 238],\n",
      "          [217, 214, 232,  ..., 224, 231, 241],\n",
      "          ...,\n",
      "          [200, 202, 230,  ..., 215, 216, 225],\n",
      "          [182, 178, 183,  ..., 214, 216, 244],\n",
      "          [199, 189, 169,  ..., 230, 224, 235]]],\n",
      "\n",
      "\n",
      "        [[[148, 156, 132,  ..., 210, 210, 237],\n",
      "          [141, 152, 139,  ..., 229, 244, 233],\n",
      "          [153, 138, 109,  ..., 222, 215, 197],\n",
      "          ...,\n",
      "          [204, 206, 231,  ..., 236, 229, 216],\n",
      "          [221, 217, 246,  ..., 241, 209, 211],\n",
      "          [221, 219, 232,  ..., 251, 215, 198]],\n",
      "\n",
      "         [[125, 133, 109,  ..., 163, 162, 190],\n",
      "          [116, 130, 119,  ..., 183, 196, 185],\n",
      "          [126, 116,  90,  ..., 177, 168, 148],\n",
      "          ...,\n",
      "          [179, 185, 213,  ..., 190, 184, 173],\n",
      "          [196, 195, 229,  ..., 195, 163, 167],\n",
      "          [195, 198, 213,  ..., 210, 169, 155]],\n",
      "\n",
      "         [[194, 211, 195,  ..., 220, 220, 245],\n",
      "          [188, 207, 200,  ..., 233, 250, 247],\n",
      "          [202, 193, 168,  ..., 225, 219, 212],\n",
      "          ...,\n",
      "          [212, 213, 238,  ..., 243, 237, 224],\n",
      "          [230, 224, 253,  ..., 248, 220, 220],\n",
      "          [232, 227, 238,  ..., 254, 231, 209]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[196, 196, 205,  ..., 218, 199, 150],\n",
      "          [196, 198, 206,  ..., 187, 212, 205],\n",
      "          [195, 203, 212,  ..., 152, 217, 255],\n",
      "          ...,\n",
      "          [104, 107, 107,  ...,  84,  65,  70],\n",
      "          [105, 106, 107,  ...,  84,  65,  72],\n",
      "          [106, 105, 107,  ...,  98,  73,  79]],\n",
      "\n",
      "         [[137, 140, 150,  ..., 206, 183, 124],\n",
      "          [138, 142, 152,  ..., 170, 195, 192],\n",
      "          [139, 147, 160,  ..., 128, 196, 255],\n",
      "          ...,\n",
      "          [ 61,  64,  63,  ...,  66,  55,  55],\n",
      "          [ 62,  63,  62,  ...,  63,  49,  53],\n",
      "          [ 63,  61,  62,  ...,  76,  54,  57]],\n",
      "\n",
      "         [[209, 209, 217,  ..., 255, 244, 213],\n",
      "          [210, 211, 218,  ..., 220, 237, 235],\n",
      "          [209, 216, 224,  ..., 178, 225, 255],\n",
      "          ...,\n",
      "          [140, 147, 150,  ..., 141, 131, 126],\n",
      "          [142, 147, 152,  ..., 154, 142, 130],\n",
      "          [145, 147, 153,  ..., 171, 152, 134]]],\n",
      "\n",
      "\n",
      "        [[[203, 218, 213,  ..., 203, 200, 225],\n",
      "          [196, 221, 209,  ..., 219, 197, 207],\n",
      "          [214, 216, 170,  ..., 208, 206, 210],\n",
      "          ...,\n",
      "          [188, 180, 160,  ..., 230, 204, 185],\n",
      "          [163, 177, 169,  ..., 235, 194, 173],\n",
      "          [160, 179, 172,  ..., 208, 194, 178]],\n",
      "\n",
      "         [[143, 159, 156,  ..., 152, 150, 175],\n",
      "          [136, 162, 152,  ..., 168, 145, 156],\n",
      "          [156, 158, 113,  ..., 155, 154, 156],\n",
      "          ...,\n",
      "          [138, 132, 113,  ..., 195, 164, 140],\n",
      "          [113, 128, 121,  ..., 198, 155, 129],\n",
      "          [110, 129, 122,  ..., 170, 154, 134]],\n",
      "\n",
      "         [[200, 214, 208,  ..., 203, 200, 225],\n",
      "          [196, 221, 208,  ..., 218, 195, 206],\n",
      "          [217, 221, 175,  ..., 206, 203, 206],\n",
      "          ...,\n",
      "          [212, 201, 176,  ..., 241, 216, 195],\n",
      "          [186, 201, 194,  ..., 246, 205, 183],\n",
      "          [185, 203, 198,  ..., 220, 204, 185]]],\n",
      "\n",
      "\n",
      "        [[[232, 219, 219,  ..., 242, 242, 242],\n",
      "          [224, 215, 215,  ..., 242, 242, 243],\n",
      "          [215, 219, 223,  ..., 242, 243, 243],\n",
      "          ...,\n",
      "          [244, 243, 243,  ..., 242, 242, 242],\n",
      "          [244, 243, 243,  ..., 241, 241, 242],\n",
      "          [243, 243, 243,  ..., 240, 241, 241]],\n",
      "\n",
      "         [[156, 142, 142,  ..., 238, 238, 238],\n",
      "          [148, 137, 138,  ..., 239, 238, 238],\n",
      "          [136, 140, 144,  ..., 239, 239, 238],\n",
      "          ...,\n",
      "          [241, 240, 240,  ..., 242, 242, 242],\n",
      "          [240, 240, 240,  ..., 242, 242, 242],\n",
      "          [240, 240, 240,  ..., 241, 242, 242]],\n",
      "\n",
      "         [[204, 191, 192,  ..., 243, 243, 242],\n",
      "          [196, 185, 185,  ..., 243, 243, 242],\n",
      "          [184, 188, 192,  ..., 243, 243, 243],\n",
      "          ...,\n",
      "          [244, 244, 244,  ..., 242, 242, 242],\n",
      "          [244, 243, 243,  ..., 242, 241, 241],\n",
      "          [243, 243, 243,  ..., 241, 241, 241]]]], dtype=torch.uint8)\n",
      "5\n",
      "Namespace(batch_size=64, learning_rate=0.001, betas=(0.9, 0.999), weight_decay=0, initial_bias=0, channels_out_init=32, channel_mul=2.0, network_depth=3, skip_features='concat', block_width=2, kernel_size=5, padding=2, stride=1, dilation=1, pool_type='max', pool_kernel_size=2, padding_convT=[1, 0, 0, 0])\n",
      "Using cpu device for training\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(cfg\u001b[38;5;241m.\u001b[39ma)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mconfig_Unet)\n\u001b[1;32m---> 16\u001b[0m t \u001b[38;5;241m=\u001b[39m Trainer(cfg\u001b[38;5;241m.\u001b[39mconfig_Unet, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[67], line 22\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, config, model)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m device for training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Move models to available device\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Optimizer\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlrate, betas\u001b[38;5;241m=\u001b[39m(beta1, beta2), weight_decay\u001b[38;5;241m=\u001b[39mwd)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import net_config as cfg\n",
    "\n",
    "x = torch.load('tensor_images.pt')\n",
    "y = torch.load('tensor_labels.pt')\n",
    "\n",
    "print(x.dtype)\n",
    "print(y.dtype)\n",
    "\n",
    "data = Lizard_dataset(\"tensor_images.pt\", \"tensor_labels.pt\")\n",
    "\n",
    "print(y)\n",
    "\n",
    "print(cfg.a)\n",
    "print(cfg.config_Unet)\n",
    "\n",
    "t = Trainer(cfg.config_Unet, None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
