{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a14d939",
   "metadata": {},
   "source": [
    "# Dataset __Bioresponse__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79fc1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce28cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bioresponse.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc40191",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81791e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         D1        D2    D3   D4        D5        D6        D7        D8  \\\n",
      "0  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166  0.585445   \n",
      "1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105  0.411754   \n",
      "2  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453  0.517720   \n",
      "3  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606  0.288764   \n",
      "4  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361  0.303809   \n",
      "\n",
      "         D9       D10  ...  D1768  D1769  D1770  D1771  D1772  D1773  D1774  \\\n",
      "0  0.743663  0.243144  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1  0.836582  0.106480  ...    1.0    1.0    1.0    0.0    1.0    0.0    0.0   \n",
      "2  0.679051  0.352308  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3  0.805110  0.208989  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4  0.812646  0.125177  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   D1775  D1776  target  \n",
      "0    0.0    0.0       1  \n",
      "1    1.0    0.0       1  \n",
      "2    0.0    0.0       1  \n",
      "3    0.0    0.0       1  \n",
      "4    0.0    0.0       0  \n",
      "\n",
      "[5 rows x 1777 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3751 entries, 0 to 3750\n",
      "Columns: 1777 entries, D1 to target\n",
      "dtypes: float64(1776), int64(1)\n",
      "memory usage: 50.9 MB\n",
      "None\n",
      "                D1           D2           D3           D4           D5  \\\n",
      "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
      "mean      0.076948     0.592436     0.068142     0.038990     0.212112   \n",
      "std       0.079989     0.105860     0.078414     0.115885     0.102592   \n",
      "min       0.000000     0.282128     0.000000     0.000000     0.002630   \n",
      "25%       0.033300     0.517811     0.000000     0.000000     0.138118   \n",
      "50%       0.066700     0.585989     0.050000     0.000000     0.190926   \n",
      "75%       0.100000     0.668395     0.100000     0.000000     0.261726   \n",
      "max       1.000000     0.964381     0.950000     1.000000     1.000000   \n",
      "\n",
      "                D6           D7           D8           D9          D10  ...  \\\n",
      "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000  ...   \n",
      "mean      0.686653     0.274713     0.455133     0.749517     0.270411  ...   \n",
      "std       0.078702     0.090017     0.162731     0.071702     0.096128  ...   \n",
      "min       0.137873     0.006130     0.000000     0.275590     0.003040  ...   \n",
      "25%       0.625627     0.207374     0.378062     0.707339     0.194357  ...   \n",
      "50%       0.674037     0.277845     0.499942     0.738961     0.284316  ...   \n",
      "75%       0.740663     0.335816     0.569962     0.788177     0.344626  ...   \n",
      "max       0.994735     0.790831     0.989870     1.000000     1.000000  ...   \n",
      "\n",
      "             D1768        D1769        D1770        D1771        D1772  \\\n",
      "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
      "mean      0.014663     0.013863     0.021861     0.015196     0.016796   \n",
      "std       0.120215     0.116938     0.146249     0.122348     0.128522   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "             D1773        D1774        D1775        D1776       target  \n",
      "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000  \n",
      "mean      0.012263     0.011730     0.020261     0.011197     0.542255  \n",
      "std       0.110074     0.107683     0.140911     0.105236     0.498278  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       0.000000     0.000000     0.000000     0.000000     1.000000  \n",
      "75%       0.000000     0.000000     0.000000     0.000000     1.000000  \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "\n",
      "[8 rows x 1777 columns]\n",
      "D1        float64\n",
      "D2        float64\n",
      "D3        float64\n",
      "D4        float64\n",
      "D5        float64\n",
      "           ...   \n",
      "D1773     float64\n",
      "D1774     float64\n",
      "D1775     float64\n",
      "D1776     float64\n",
      "target      int64\n",
      "Length: 1777, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3de8200",
   "metadata": {},
   "source": [
    "Each row in this data set represents a molecule. The first column contains experimental data describing an actual biological response; the molecule was seen to elicit this response (1), or not (0). The remaining columns represent molecular descriptors (d1 through d1776), these are calculated properties that can capture some of the characteristics of the molecule - for example size, shape, or elemental constitution. The \"target\" column is the biological response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846b82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['target']) # Input features (molecular descriptors)\n",
    "Y = data['target'] # Target variable (biological response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef59300",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78533dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target value distribution\n",
    "def target_distribution(data):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x='target', data=data, palette='pastel')\n",
    "    plt.title('Distribution of the target value')\n",
    "    plt.xlabel('Target Variable')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "# Boxplots for the first N descriptors\n",
    "def firstN_descriptors(data, num):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(data=data.iloc[:, 1:num])\n",
    "    plt.title('Boxplot of Molecular Descriptors (d1-d10)')\n",
    "    plt.xlabel('Descriptor')\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()\n",
    "\n",
    "# Visualisation of the relationship between the first molecular descriptor (X1) and the target variable\n",
    "def descriptor_target_relationship(data, idx):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=data['target'], y=data.iloc[:, idx], color='lightgreen')\n",
    "    plt.title('Relationship between the first descriptor and Target Variable')\n",
    "    plt.xlabel('Target Variable')\n",
    "    plt.ylabel('X')\n",
    "    plt.show()\n",
    "\n",
    "def heatmaps_corr(data):\n",
    "    X = data.drop(columns=['target']) # Input features (molecular descriptors)\n",
    "    Y = data['target'] # Target variable (biological response)\n",
    "\n",
    "    correlation_X = X.corr()  # Correlation among molecular descriptors\n",
    "    correlation_Y = X.apply(lambda x: x.corr(Y))  # Correlation between each molecular descriptor and the target variable\n",
    "\n",
    "    # Heatmap for correlation among molecular descriptors\n",
    "    sns.heatmap(correlation_X, cmap='coolwarm', annot=False, ax=axes[0])\n",
    "    axes[0].set_title('Correlation Heatmap - Molecular Descriptors')\n",
    "    axes[0].set_xlabel('Molecular Descriptors')\n",
    "    axes[0].set_ylabel('Molecular Descriptors')\n",
    "\n",
    "    # Heatmap for correlation between molecular descriptors and target variable\n",
    "    sns.heatmap(correlation_Y.to_frame().transpose(), cmap='coolwarm', annot=True, fmt=\".2f\", ax=axes[1])\n",
    "    axes[1].set_title('Correlation Heatmap - Molecular Descriptors vs. Target Variable')\n",
    "    axes[1].set_xlabel('Molecular Descriptors')\n",
    "    axes[1].set_ylabel('Target Variable (Y)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ea8c1",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6d6f21",
   "metadata": {},
   "source": [
    "#### Merging descriptors with similar correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16cf4bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_threshold = treshold for correlation to merge descriptors (bigger corr => merget descriptors) \n",
    "def merge_descriptors(data, correlation_threshold = 0.5):\n",
    "    correlation_matrix = data.corr()\n",
    "    merged_descriptors = set()\n",
    "\n",
    "    # Iterate over the correlation matrix to identify pairs of descriptors with similar correlation\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) >= correlation_threshold:\n",
    "                # Add correlated descriptors to the set\n",
    "                merged_descriptors.add((correlation_matrix.columns[i], correlation_matrix.columns[j]))\n",
    "\n",
    "    merged_data = data.copy()\n",
    "\n",
    "    # Merge descriptors\n",
    "    for descriptor_pair in merged_descriptors:\n",
    "        # Check if both descriptors exist in the dataset\n",
    "        if all(descriptor in merged_data.columns for descriptor in descriptor_pair):\n",
    "            merged_descriptor_name = '_'.join(descriptor_pair)\n",
    "            merged_data[merged_descriptor_name] = (data[descriptor_pair[0]] + data[descriptor_pair[1]]) / 2\n",
    "            merged_data.drop(list(descriptor_pair), axis=1, inplace=True)\n",
    "\n",
    "    print(\"Information about Merged DataFrame:\")\n",
    "    print(merged_data.info())\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37daf77",
   "metadata": {},
   "source": [
    "#### Linear correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7055a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_selection_original(data, correlation_threshold = 0.2):\n",
    "    selected_features = correlation_Y[correlation_Y >= correlation_threshold].index.tolist()\n",
    "\n",
    "    selected_data = data[selected_features]\n",
    "\n",
    "    print(\"Selected Features from original data:\")\n",
    "    print(selected_features)\n",
    "    \n",
    "    return pd.DataFrame(data=data[selected_features + ['target']])\n",
    "\n",
    "def correlation_selection_merged(data, correlation_threshold = 0.2):\n",
    "    correlation_matrix = data.corr()\n",
    "\n",
    "    correlation_threshold_m = 0.5  # Adjust as needed\n",
    "\n",
    "    merged_descriptors = set()\n",
    "\n",
    "    # Iterate over the correlation matrix to identify pairs of descriptors with similar correlation\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) >= correlation_threshold_m:\n",
    "                # Add correlated descriptors to the set\n",
    "                merged_descriptors.add((correlation_matrix.columns[i], correlation_matrix.columns[j]))\n",
    "\n",
    "    merged_data = data.copy()\n",
    "\n",
    "    # Merge descriptors\n",
    "    for descriptor_pair in merged_descriptors:\n",
    "        # Check if both descriptors exist in the dataset\n",
    "        if all(descriptor in merged_data.columns for descriptor in descriptor_pair):\n",
    "            merged_descriptor_name = '_'.join(descriptor_pair)\n",
    "            merged_data[merged_descriptor_name] = (data[descriptor_pair[0]] + data[descriptor_pair[1]]) / 2\n",
    "            merged_data.drop(list(descriptor_pair), axis=1, inplace=True)\n",
    "            \n",
    "    X_m = merged_data.drop(columns=['target']) # Input features (molecular descriptors)\n",
    "    Y_m = merged_data['target'] # Target variable (biological response)\n",
    "\n",
    "    correlation_Y_m = X_m.apply(lambda x: x.corr(Y_m))\n",
    "    selected_features_m = correlation_Y_m[correlation_Y_m >= correlation_threshold].index.tolist()\n",
    "\n",
    "    selected_data_m = merged_data[selected_features_m]\n",
    "\n",
    "    print(\"Selected Features from merged data:\")\n",
    "    print(selected_features_m)\n",
    "    \n",
    "    return pd.DataFrame(data=merged_data[selected_features_m + ['target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ddb75",
   "metadata": {},
   "source": [
    "As you can see, the linear correlation is not too high between the target_value and the descriptors, so I have to experiment fith another feature selection methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3738b",
   "metadata": {},
   "source": [
    "#### Tree based selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddaab513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_based_original(data, n_estimators=100, top_n=50, random_state=42):\n",
    "    X = data.drop(columns=['target'])\n",
    "    Y = data['target']\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "    rf.fit(X, Y)\n",
    "\n",
    "    feature_importances = rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "    top_features = importance_df['Feature'].head(top_n).tolist()\n",
    "    \n",
    "    print(\"Top features:\")\n",
    "    top_features[:5]\n",
    "    \n",
    "    return pd.DataFrame(data=data[top_features + ['target']]) \n",
    "\n",
    "def tree_based_merged(data, n_estimators=100, top_n=50, random_state=42):\n",
    "    correlation_matrix = data.corr()\n",
    "\n",
    "    correlation_threshold = 0.5  # Adjust as needed\n",
    "\n",
    "    merged_descriptors = set()\n",
    "\n",
    "    # Iterate over the correlation matrix to identify pairs of descriptors with similar correlation\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) >= correlation_threshold:\n",
    "                # Add correlated descriptors to the set\n",
    "                merged_descriptors.add((correlation_matrix.columns[i], correlation_matrix.columns[j]))\n",
    "\n",
    "    merged_data = data.copy()\n",
    "\n",
    "    # Merge descriptors\n",
    "    for descriptor_pair in merged_descriptors:\n",
    "        # Check if both descriptors exist in the dataset\n",
    "        if all(descriptor in merged_data.columns for descriptor in descriptor_pair):\n",
    "            merged_descriptor_name = '_'.join(descriptor_pair)\n",
    "            merged_data[merged_descriptor_name] = (data[descriptor_pair[0]] + data[descriptor_pair[1]]) / 2\n",
    "            merged_data.drop(list(descriptor_pair), axis=1, inplace=True)\n",
    "            \n",
    "    X_m = merged_data.drop(columns=['target'])\n",
    "    Y_m = merged_data['target']\n",
    "    \n",
    "    rf_m = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "    rf_m.fit(X_m, Y_m)\n",
    "\n",
    "    feature_importances_m = rf_m.feature_importances_\n",
    "    importance_df_m = pd.DataFrame({'Feature': X_m.columns, 'Importance': feature_importances_m})\n",
    "    importance_df_m = importance_df_m.sort_values(by='Importance', ascending=False)\n",
    "    top_features_m = importance_df_m['Feature'].head(top_n).tolist()\n",
    "    \n",
    "    print(\"Top featuresmerged:\")\n",
    "    top_features_m[:5]\n",
    "    \n",
    "    return pd.DataFrame(data=merged_data[top_features_m + ['target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1533156f",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9027e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def pca(data, n_components=50):\n",
    "    X = data.drop(columns=['target'])\n",
    "    y = data['target']\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    pca.fit(X_scaled)\n",
    "\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "\n",
    "    pca_scaler = StandardScaler()\n",
    "    X_pca_normalized = pca_scaler.fit_transform(X_pca)\n",
    "\n",
    "    principal_components_df = pd.DataFrame(data=X_pca_normalized, columns=[f'PC{i+1}_normalized' for i in range(n_components)])\n",
    "    \n",
    "    principal_components_df['target'] = data['target']\n",
    "    \n",
    "    return principal_components_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff3a4873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1_normalized</th>\n",
       "      <th>PC2_normalized</th>\n",
       "      <th>PC3_normalized</th>\n",
       "      <th>PC4_normalized</th>\n",
       "      <th>PC5_normalized</th>\n",
       "      <th>PC6_normalized</th>\n",
       "      <th>PC7_normalized</th>\n",
       "      <th>PC8_normalized</th>\n",
       "      <th>PC9_normalized</th>\n",
       "      <th>PC10_normalized</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.907717</td>\n",
       "      <td>0.482206</td>\n",
       "      <td>-0.128484</td>\n",
       "      <td>-1.849404</td>\n",
       "      <td>-0.999578</td>\n",
       "      <td>-0.273188</td>\n",
       "      <td>0.248699</td>\n",
       "      <td>-0.300778</td>\n",
       "      <td>-0.486060</td>\n",
       "      <td>-0.067402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.076563</td>\n",
       "      <td>2.084961</td>\n",
       "      <td>4.734596</td>\n",
       "      <td>-0.115921</td>\n",
       "      <td>-0.171535</td>\n",
       "      <td>-0.405104</td>\n",
       "      <td>-1.775952</td>\n",
       "      <td>-0.266095</td>\n",
       "      <td>2.011384</td>\n",
       "      <td>3.067987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.943033</td>\n",
       "      <td>0.637368</td>\n",
       "      <td>0.125603</td>\n",
       "      <td>-0.627555</td>\n",
       "      <td>-1.239454</td>\n",
       "      <td>0.095470</td>\n",
       "      <td>0.971724</td>\n",
       "      <td>-0.876554</td>\n",
       "      <td>0.191216</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.936173</td>\n",
       "      <td>0.762274</td>\n",
       "      <td>-0.164366</td>\n",
       "      <td>0.214169</td>\n",
       "      <td>0.026790</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>-0.007323</td>\n",
       "      <td>-0.446322</td>\n",
       "      <td>-0.738950</td>\n",
       "      <td>0.255671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.113560</td>\n",
       "      <td>1.071062</td>\n",
       "      <td>-0.330413</td>\n",
       "      <td>1.623841</td>\n",
       "      <td>1.105684</td>\n",
       "      <td>0.193087</td>\n",
       "      <td>-0.945600</td>\n",
       "      <td>0.342518</td>\n",
       "      <td>0.104023</td>\n",
       "      <td>0.372876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>0.049068</td>\n",
       "      <td>-1.402846</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>-0.783234</td>\n",
       "      <td>2.404541</td>\n",
       "      <td>0.956580</td>\n",
       "      <td>1.249742</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>-1.064347</td>\n",
       "      <td>-0.373697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>1.395941</td>\n",
       "      <td>1.635597</td>\n",
       "      <td>2.839070</td>\n",
       "      <td>0.377879</td>\n",
       "      <td>0.461329</td>\n",
       "      <td>-1.984444</td>\n",
       "      <td>-1.197600</td>\n",
       "      <td>-1.075677</td>\n",
       "      <td>-1.526109</td>\n",
       "      <td>0.103762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>0.869268</td>\n",
       "      <td>0.859314</td>\n",
       "      <td>-0.360736</td>\n",
       "      <td>1.922090</td>\n",
       "      <td>-1.600359</td>\n",
       "      <td>-0.737172</td>\n",
       "      <td>0.034640</td>\n",
       "      <td>2.002952</td>\n",
       "      <td>1.144269</td>\n",
       "      <td>-0.385626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>-0.863932</td>\n",
       "      <td>0.578126</td>\n",
       "      <td>0.058405</td>\n",
       "      <td>0.760917</td>\n",
       "      <td>-1.031633</td>\n",
       "      <td>-0.625317</td>\n",
       "      <td>1.008153</td>\n",
       "      <td>0.088348</td>\n",
       "      <td>-0.772715</td>\n",
       "      <td>0.750037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>-1.101195</td>\n",
       "      <td>1.115593</td>\n",
       "      <td>-0.257506</td>\n",
       "      <td>1.418716</td>\n",
       "      <td>0.875983</td>\n",
       "      <td>0.025212</td>\n",
       "      <td>-0.627484</td>\n",
       "      <td>0.143228</td>\n",
       "      <td>0.480138</td>\n",
       "      <td>0.085682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3751 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PC1_normalized  PC2_normalized  PC3_normalized  PC4_normalized  \\\n",
       "0          -0.907717        0.482206       -0.128484       -1.849404   \n",
       "1           2.076563        2.084961        4.734596       -0.115921   \n",
       "2          -0.943033        0.637368        0.125603       -0.627555   \n",
       "3          -0.936173        0.762274       -0.164366        0.214169   \n",
       "4          -1.113560        1.071062       -0.330413        1.623841   \n",
       "...              ...             ...             ...             ...   \n",
       "3746        0.049068       -1.402846        0.011396       -0.783234   \n",
       "3747        1.395941        1.635597        2.839070        0.377879   \n",
       "3748        0.869268        0.859314       -0.360736        1.922090   \n",
       "3749       -0.863932        0.578126        0.058405        0.760917   \n",
       "3750       -1.101195        1.115593       -0.257506        1.418716   \n",
       "\n",
       "      PC5_normalized  PC6_normalized  PC7_normalized  PC8_normalized  \\\n",
       "0          -0.999578       -0.273188        0.248699       -0.300778   \n",
       "1          -0.171535       -0.405104       -1.775952       -0.266095   \n",
       "2          -1.239454        0.095470        0.971724       -0.876554   \n",
       "3           0.026790        0.009333       -0.007323       -0.446322   \n",
       "4           1.105684        0.193087       -0.945600        0.342518   \n",
       "...              ...             ...             ...             ...   \n",
       "3746        2.404541        0.956580        1.249742        0.241699   \n",
       "3747        0.461329       -1.984444       -1.197600       -1.075677   \n",
       "3748       -1.600359       -0.737172        0.034640        2.002952   \n",
       "3749       -1.031633       -0.625317        1.008153        0.088348   \n",
       "3750        0.875983        0.025212       -0.627484        0.143228   \n",
       "\n",
       "      PC9_normalized  PC10_normalized  target  \n",
       "0          -0.486060        -0.067402       1  \n",
       "1           2.011384         3.067987       1  \n",
       "2           0.191216         0.124700       1  \n",
       "3          -0.738950         0.255671       1  \n",
       "4           0.104023         0.372876       0  \n",
       "...              ...              ...     ...  \n",
       "3746       -1.064347        -0.373697       1  \n",
       "3747       -1.526109         0.103762       1  \n",
       "3748        1.144269        -0.385626       0  \n",
       "3749       -0.772715         0.750037       1  \n",
       "3750        0.480138         0.085682       0  \n",
       "\n",
       "[3751 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca(data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01bed4e",
   "metadata": {},
   "source": [
    "Calling functions and viewing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9532174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data = correlation_selection_merged(data)\n",
    "#new_data = tree_based_merged(data)\n",
    "#new_data = pca(data, n_components = 10)\n",
    "\n",
    "#new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849bf7a",
   "metadata": {},
   "source": [
    "### Polynomial feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71ffd59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_float32 = data.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f450548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# # Feature Engineering\n",
    "# poly = PolynomialFeatures(degree=1.5, interaction_only=True, include_bias=False)\n",
    "# X_poly = poly.fit_transform(X)\n",
    "\n",
    "# # Convert the polynomial feature matrix to a DataFrame\n",
    "# X_poly_df = pd.DataFrame(X_poly, columns=poly.get_feature_names_out(X.columns))\n",
    "\n",
    "# # Concatenate the original features with the polynomial features\n",
    "# X_combined = pd.concat([X, X_poly_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394f5cf",
   "metadata": {},
   "source": [
    "This method occures memory problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d7003",
   "metadata": {},
   "source": [
    "## Summary of the feature selection\n",
    "We created a feature selection according to linear correlation for original data, and tried to merge the descriptors with similar correlation value in relation with the target value. [selected_features, selected_features_m] \n",
    "\n",
    "\n",
    "We also selected features using tree based feature selection method using the original and the merged data. These lists represents the top 50 features. [top_features, top_features_m]\n",
    "\n",
    "\n",
    "We tried polynomial feature selection as well, but in this case we had memory problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d2623",
   "metadata": {},
   "source": [
    "#### Selected features dataframe export functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4edaea",
   "metadata": {},
   "source": [
    "You can get the dataframes, which are containing the specific selected features with calling: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059ad2b8",
   "metadata": {},
   "source": [
    "correlation_selection_original(data, correlation_threshold), correlation_selection_merged(data, correlation_threshold), tree_based_original(data, n_estimators, top_n, random_state), tree_based_merged(data, n_estimators, top_n, random_state), pca(data, n_components)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
