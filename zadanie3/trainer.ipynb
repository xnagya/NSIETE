{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Model trainer__\n",
    "This file contains Trainer and Statistics classes used during training of NN models. All metrics are calculated using library _torchmetrics_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassAUROC\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import net_config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, file_essay, file_missing):\n",
    "        essay_arr = np.load(file_essay)\n",
    "        indexes_arr = np.load(file_missing, allow_pickle=True)\n",
    "\n",
    "        assert (essay_arr.shape[0] == indexes_arr.shape[0]), f\"Wrong dataset size, essey count = {essay_arr.shape[0]} indexes count = {indexes_arr.shape[0]}\"\n",
    "        essey_count = essay_arr.shape[0]\n",
    "\n",
    "        self.inputs = torch.from_numpy(essay_arr).type(torch.int32)\n",
    "\n",
    "        # List of tensors with target words\n",
    "        self.targets = []\n",
    "\n",
    "        # List of tensors with missing words index\n",
    "        self.missing_positions = []\n",
    "\n",
    "        # Extract missing words and their positions from numpy\n",
    "        for i in range(essey_count):\n",
    "            missing_words = []\n",
    "            missing_pos = []\n",
    "\n",
    "            for pair in indexes_arr[i]:\n",
    "                pos = pair[0]\n",
    "                word_idx = pair[1]\n",
    "\n",
    "                missing_pos.append(pos)\n",
    "                missing_words.append(word_idx)\n",
    "\n",
    "            self.missing_positions.append(torch.tensor(missing_pos, dtype=torch.int32))\n",
    "            self.targets.append(torch.tensor(missing_words, dtype=torch.int32))\n",
    "\n",
    "            # Set missing word count per essay\n",
    "            if (i == 0): \n",
    "                self.missing_per_essay = len(missing_words)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.inputs[idx]\n",
    "        pos = self.missing_positions[idx]\n",
    "        y = self.targets[idx]\n",
    "\n",
    "        return x, pos, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 110,   62,    2,   50,   62,    2,   50,   -1,  110,  134,  107,   10,\n",
      "          72,  199,  112,  133,  153,   93,  282,  307,  440,  600,   72,  207,\n",
      "         406,   95, 1935, 2819, 1481,   94, 1570,  462,  101,   86,   51,    2,\n",
      "          50,  423,    8,   53,  297,  245,  107,  434,  115,  167,    2,  492,\n",
      "         297, 1107], dtype=torch.int32)\n",
      "tensor([7], dtype=torch.int32)\n",
      "tensor([564], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "file1 = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation.npy\"\n",
    "file2 = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs.npy\"\n",
    "dataset = EssayDataset(file1, file2)\n",
    "x, indices, y = dataset.__getitem__(50)\n",
    "print(x)\n",
    "print(indices)\n",
    "print(y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statistics:\n",
    "    def __init__(self):\n",
    "        self.metrics = dict()\n",
    "\n",
    "    def update(self, metric_name, new_value):\n",
    "        if metric_name in self.metrics:\n",
    "            values = self.metrics[metric_name]\n",
    "            values.append(new_value)\n",
    "        else:\n",
    "            values = [new_value]\n",
    "            self.metrics.update({metric_name : values})\n",
    "\n",
    "    def get_metric(self, metric_name):\n",
    "        return self.metrics.get(metric_name)\n",
    "    \n",
    "    def batch_count(self):\n",
    "        max = 0\n",
    "        for val in self.metrics.values():\n",
    "            if len(val) > max:\n",
    "                max = len(val)\n",
    "\n",
    "        return max \n",
    "    \n",
    "    def clear(self):\n",
    "        self.metrics = dict()\n",
    "\n",
    "    # First batch is 0\n",
    "    def batch_metrics(self, batch_num):\n",
    "        result = dict()\n",
    "        \n",
    "        for metric_name, values in self.metrics.items():\n",
    "            if (batch_num >= 0) and (batch_num < len(values)):\n",
    "                metric_val = values[batch_num]\n",
    "                result.update({metric_name : metric_val})\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def metric_average(self, metric_name):\n",
    "        if metric_name in self.metrics:\n",
    "            values = self.metrics[metric_name]\n",
    "            return float(sum(values) / len(values))\n",
    "        \n",
    "        else: \n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model: nn.Module, vocab_size):\n",
    "        # Select GPU device\n",
    "        self.device = (\n",
    "            \"cuda\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "\n",
    "        print(f\"Using {self.device} device for training\")\n",
    "\n",
    "        # Move model to available device\n",
    "        self.network = model.to(self.device)\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.network.parameters()\n",
    "            , lr = cfg.learning_rate\n",
    "            , betas = cfg.betas\n",
    "            , weight_decay = cfg.weight_decay\n",
    "        )\n",
    "\n",
    "        # Loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Class for saving metrics\n",
    "        self.stats = Statistics()\n",
    "\n",
    "        # Metrics \n",
    "        self.acc = MulticlassAccuracy(\n",
    "            num_classes = vocab_size\n",
    "            , average = \"weighted\"\n",
    "            )\n",
    "        self.roc = MulticlassAUROC(\n",
    "            num_classes = vocab_size\n",
    "            , average = \"weighted\"\n",
    "        )\n",
    "        self.f1 = MulticlassF1Score(\n",
    "            num_classes = vocab_size\n",
    "            , average = \"weighted\"\n",
    "        )\n",
    "\n",
    "        # Saving and loading model\n",
    "        self.best_model = None\n",
    "        self.best_accuracy = None\n",
    "\n",
    "    def load_dataset(self, essay_path, positions_path):\n",
    "        # Load dataset\n",
    "        dataset = EssayDataset(essay_path, positions_path)\n",
    "        \n",
    "        # Split dataset to train, validation and test \n",
    "        gen = torch.Generator().manual_seed(42)\n",
    "        data_train, data_val, data_test = random_split(dataset, [0.7, 0.15, 0.15], generator=gen)\n",
    "\n",
    "        # Create dataset loaders\n",
    "        self.data_train = DataLoader(data_train, batch_size = cfg.batch_size, shuffle = True)\n",
    "        self.data_val = DataLoader(data_val, batch_size = cfg.batch_size, shuffle = True)\n",
    "        self.data_test = DataLoader(data_test, batch_size = cfg.batch_size, shuffle = False)\n",
    "\n",
    "    def save_model(self, current_epoch):  \n",
    "        if self.best_model is not None:\n",
    "            checkpoint = {\n",
    "                'epoch': current_epoch,\n",
    "                'NNmodel': self.best_model.state_dict(),\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(checkpoint, cfg.model_path)\n",
    "            print(f\"NN model saved at path '{cfg.model_path}'\")\n",
    "\n",
    "    def load_model(self):\n",
    "        checkpoint = torch.load(cfg.model_path)\n",
    "\n",
    "        self.network.load_state_dict(checkpoint['NNmodel'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "        self.test_model()\n",
    "\n",
    "        print(f\"NN model loaded from path '{cfg.model_path}'\")\n",
    "        return checkpoint['epoch']\n",
    "\n",
    "    def train_model(self):\n",
    "        # Train model (dataset = data_train)\n",
    "        self.network.train()\n",
    "        start = time.time()\n",
    "\n",
    "        for x, pos, y in self.data_train:\n",
    "            x, pos, y = x.to(self.device), pos.t(self.device), y.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            x = self.network(x, pos)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = self.loss_fn(x, y)\n",
    "\n",
    "            # Save batch loss\n",
    "            self.stats.update(\"loss_train\", loss)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            grad_norm1 = torch.nn.utils.clip_grad_norm(self.network.parameters(), cfg.grad_clip)\n",
    "            grad_norm2 = np.sqrt(sum([torch.norm(p.grad)**2 for p in self.network.parameters()]))\n",
    "\n",
    "            # TODO - log grad norm\n",
    "            print(f\"GRAD NORM (torch) = {grad_norm1}\")\n",
    "            print(f\"GRAD NORM (manual) = {grad_norm2}\")\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"Train time in sec = {end - start}\")\n",
    "\n",
    "        # Evaulate model by calculating loss (dataset = data_val)\n",
    "        self.network.eval()\n",
    "        start = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, pos, y in self.data_val:\n",
    "                x, pos, y = x.to(self.device), pos.t(self.device), y.to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                x = self.network(x, pos)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = self.loss_fn(x, y)\n",
    "\n",
    "                # Save batch loss\n",
    "                self.stats.update(\"loss_val\", loss)\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"Validation time in sec = {end - start}\")\n",
    "\n",
    "    # Test model by calculating metrics (dataset = data_test) and keep the best model\n",
    "    def test_model(self):\n",
    "        self.network.eval()\n",
    "        start = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, pos, y in self.data_test:\n",
    "                x, pos, y = x.to(self.device), pos.t(self.device), y.to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                x = self.network(x, pos)\n",
    "\n",
    "                classes = torch.argmax(x, dim=2)\n",
    "                confidence = torch.softmax(x, dim=2)\n",
    "\n",
    "                # Calculate metrics\n",
    "                accuracy = self.acc(classes, y).item()\n",
    "                self.stats.update(\"acc\", accuracy)\n",
    "                self.stats.update(\"f1\", self.f1(classes, y).item())\n",
    "                self.stats.update(\"auroc\", self.roc(confidence, y).item())\n",
    "                \n",
    "        end = time.time()\n",
    "        print(f\"Test time in sec = {end - start}\")\n",
    "\n",
    "        # Save best model\n",
    "        if (self.best_accuracy is None) or (self.best_accuracy < accuracy):\n",
    "            self.best_accuracy = accuracy\n",
    "            self.best_model = self.network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device for training\n",
      "Parameter containing:\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1273,  0.2398, -0.9842,  ...,  0.3069,  2.0647, -0.2825],\n",
      "        [-0.2483, -0.1048, -1.7399,  ...,  0.2334, -1.0775, -0.5022],\n",
      "        ...,\n",
      "        [ 1.3085,  0.1757, -0.8272,  ...,  0.4023,  1.3177,  2.7058],\n",
      "        [ 1.2090,  0.2231, -0.1258,  ...,  0.3745,  0.5182,  2.3419],\n",
      "        [ 0.5385, -1.6594,  0.6727,  ..., -0.0409,  0.2593, -1.6582]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0706,  0.0835,  0.1618,  ..., -0.1117,  0.1225,  0.0927],\n",
      "        [-0.1629,  0.1001,  0.0054,  ..., -0.1744, -0.1379,  0.1397],\n",
      "        [-0.0903,  0.1287,  0.1167,  ...,  0.1633,  0.0596, -0.0903],\n",
      "        ...,\n",
      "        [-0.0513, -0.0077, -0.1764,  ...,  0.1077, -0.0407,  0.1297],\n",
      "        [-0.0596,  0.0762, -0.0273,  ...,  0.1663, -0.1055,  0.0679],\n",
      "        [ 0.1185,  0.1765, -0.1554,  ...,  0.0952,  0.0466, -0.1804]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 7.3465e-02,  1.7308e-03, -1.7449e-02,  ...,  6.6361e-02,\n",
      "          3.0014e-02, -1.1050e-02],\n",
      "        [ 8.3092e-02, -1.6926e-01,  5.9667e-02,  ...,  2.5231e-03,\n",
      "         -1.7302e-02, -1.2088e-01],\n",
      "        [-1.4100e-02,  1.7277e-01, -1.0357e-01,  ...,  1.7023e-01,\n",
      "         -1.1649e-01,  4.5915e-02],\n",
      "        ...,\n",
      "        [ 7.0381e-02,  9.3331e-02, -1.3492e-01,  ...,  8.9556e-06,\n",
      "         -9.9989e-02,  4.2918e-02],\n",
      "        [-1.4492e-01,  6.6718e-02, -1.2097e-01,  ..., -1.4723e-01,\n",
      "         -7.1860e-02,  9.6761e-02],\n",
      "        [ 3.5969e-02, -1.0899e-01, -1.2974e-01,  ...,  5.6024e-02,\n",
      "         -4.7359e-02,  2.5289e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1754,  0.1634,  0.0647,  ..., -0.0337, -0.1398,  0.1052],\n",
      "        [ 0.1747,  0.0139, -0.1235,  ...,  0.1253, -0.1792,  0.1002],\n",
      "        [-0.0276,  0.0937,  0.1763,  ..., -0.1083,  0.1566,  0.1059],\n",
      "        ...,\n",
      "        [-0.1214,  0.1532,  0.0348,  ..., -0.0065,  0.0905,  0.0190],\n",
      "        [-0.1153, -0.0669,  0.0928,  ...,  0.1003, -0.1143,  0.0313],\n",
      "        [ 0.1010, -0.1245,  0.0281,  ..., -0.1265, -0.1691,  0.0196]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1146, -0.1790,  0.1683,  ..., -0.0703,  0.1748, -0.1308],\n",
      "        [ 0.1338, -0.1763,  0.0304,  ..., -0.0759, -0.1207,  0.0671],\n",
      "        [-0.1053, -0.0179, -0.1577,  ..., -0.1857, -0.1375, -0.1812],\n",
      "        ...,\n",
      "        [ 0.1047, -0.1026,  0.1041,  ...,  0.1003,  0.1776, -0.1304],\n",
      "        [ 0.0217, -0.1679,  0.0665,  ..., -0.0537, -0.1233,  0.0407],\n",
      "        [ 0.0915, -0.1770, -0.1116,  ..., -0.0347,  0.0566, -0.1434]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1203, -0.0444, -0.0356,  ...,  0.0588,  0.1648,  0.1532],\n",
      "        [-0.0266, -0.0948,  0.0433,  ...,  0.1651, -0.0615, -0.0757],\n",
      "        [ 0.0309, -0.0352, -0.0986,  ...,  0.0006,  0.1052, -0.0683],\n",
      "        ...,\n",
      "        [-0.0220, -0.0952,  0.0909,  ..., -0.0502,  0.1171,  0.0781],\n",
      "        [-0.0868,  0.1707, -0.1723,  ..., -0.1113,  0.0793,  0.0942],\n",
      "        [-0.0094, -0.0104, -0.0064,  ..., -0.0916, -0.0227, -0.0430]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1845,  0.0304,  0.1378,  ..., -0.1308,  0.0774,  0.0653],\n",
      "        [ 0.1883,  0.0221, -0.1198,  ...,  0.0890,  0.0491,  0.1073],\n",
      "        [-0.1475, -0.1660, -0.1283,  ..., -0.0659, -0.0004,  0.1441],\n",
      "        ...,\n",
      "        [-0.1346, -0.1069,  0.0197,  ...,  0.0129, -0.1419,  0.0475],\n",
      "        [-0.1793,  0.1650, -0.0418,  ..., -0.0748, -0.1509, -0.0458],\n",
      "        [ 0.0576,  0.1333,  0.0117,  ..., -0.1218, -0.1718,  0.0909]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0441, -0.0114, -0.1543,  ...,  0.0385,  0.0388, -0.0451],\n",
      "        [ 0.1362,  0.0841,  0.0581,  ...,  0.0394, -0.0978,  0.0504],\n",
      "        [-0.1544,  0.0110, -0.0764,  ..., -0.0226, -0.1401,  0.0975],\n",
      "        ...,\n",
      "        [ 0.0301,  0.1338, -0.1148,  ..., -0.0480, -0.0846, -0.0170],\n",
      "        [ 0.1471,  0.1168, -0.1011,  ..., -0.0378,  0.0065,  0.1531],\n",
      "        [-0.1058,  0.1517, -0.1557,  ..., -0.1530, -0.1158,  0.0485]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1264,  0.1492, -0.0956,  ...,  0.0635,  0.1178,  0.0838],\n",
      "        [ 0.1238, -0.0025,  0.1779,  ..., -0.1352, -0.0969,  0.1767],\n",
      "        [ 0.1281, -0.0869,  0.1849,  ...,  0.0275, -0.1471, -0.0128],\n",
      "        ...,\n",
      "        [ 0.0160, -0.0537,  0.1903,  ...,  0.0813, -0.1495, -0.1075],\n",
      "        [-0.1311,  0.1840, -0.1784,  ...,  0.0899,  0.1408,  0.0205],\n",
      "        [-0.0950, -0.0453,  0.1896,  ..., -0.1295,  0.1840,  0.1706]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0437, -0.1227,  0.1565,  ..., -0.1584, -0.0621,  0.0586],\n",
      "        [ 0.0977,  0.0647, -0.1037,  ..., -0.0863, -0.1354,  0.1013],\n",
      "        [ 0.1214, -0.1448, -0.1761,  ...,  0.0223, -0.1538, -0.0846],\n",
      "        ...,\n",
      "        [-0.0451,  0.0498, -0.0789,  ..., -0.1714,  0.1171,  0.0160],\n",
      "        [-0.1654, -0.0474,  0.0416,  ...,  0.1165,  0.1269, -0.1630],\n",
      "        [-0.0301,  0.0676,  0.0155,  ...,  0.0690,  0.1727, -0.0434]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1704,  0.0626,  0.0963,  ..., -0.1285,  0.1820,  0.1898],\n",
      "        [ 0.1564,  0.1651, -0.1795,  ...,  0.0177,  0.1720, -0.1195],\n",
      "        [-0.0707,  0.0207, -0.1747,  ...,  0.0450, -0.0321, -0.0709],\n",
      "        ...,\n",
      "        [-0.1638, -0.0976,  0.1345,  ..., -0.1677, -0.0603, -0.0567],\n",
      "        [-0.0335, -0.1911,  0.0049,  ..., -0.0942,  0.1292,  0.1489],\n",
      "        [ 0.0283,  0.1699,  0.1633,  ...,  0.1137,  0.0536,  0.0446]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1246, -0.0901, -0.1036,  ...,  0.1665,  0.1404, -0.1493],\n",
      "        [ 0.0913, -0.1222, -0.0039,  ..., -0.1246,  0.1686,  0.0432],\n",
      "        [ 0.0543, -0.0593, -0.0369,  ..., -0.0331, -0.0005,  0.1585],\n",
      "        ...,\n",
      "        [ 0.0780, -0.0317, -0.1330,  ...,  0.0597,  0.1468,  0.0011],\n",
      "        [-0.0947,  0.1103,  0.1643,  ..., -0.1034, -0.0595, -0.0488],\n",
      "        [-0.1731,  0.0399,  0.1318,  ..., -0.0231, -0.1151, -0.0831]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1625,  0.1169,  0.1159,  ...,  0.0375,  0.1000,  0.0898],\n",
      "        [-0.1377, -0.1013,  0.1775,  ...,  0.0623, -0.1283, -0.0499],\n",
      "        [-0.1807,  0.0484,  0.0376,  ..., -0.0957,  0.0844, -0.1447],\n",
      "        ...,\n",
      "        [ 0.1363,  0.0403, -0.0595,  ..., -0.1675, -0.0667,  0.0006],\n",
      "        [-0.0413,  0.1845, -0.0216,  ..., -0.0320,  0.0417, -0.1888],\n",
      "        [-0.0648,  0.0435, -0.0646,  ..., -0.1468,  0.0849, -0.1845]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.5507, -0.4148, -0.5743,  ..., -0.8995, -0.7546, -0.8013],\n",
      "        [-1.9214,  0.6289,  0.1315,  ..., -0.2805,  1.4446,  0.0665],\n",
      "        [-1.0683,  0.9974,  1.5300,  ...,  0.8561, -0.2308, -0.4117],\n",
      "        ...,\n",
      "        [ 0.0697,  1.8815,  1.0072,  ..., -0.4890, -0.3665, -0.4427],\n",
      "        [-1.0603,  0.7131,  0.4137,  ...,  0.1245, -0.0214, -0.9356],\n",
      "        [-1.0183,  0.0201,  2.4007,  ...,  1.7107, -1.4970,  0.9569]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "\n",
    "vocab_size = 100\n",
    "\n",
    "net = models.RNN(\"lstm\", vocab_size, cfg.config_to_dict(cfg.config_NN))\n",
    "t = Trainer(net, vocab_size)\n",
    "\n",
    "path_essay = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation.npy\"\n",
    "path_pos = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs.npy\"\n",
    "\n",
    "t.load_dataset(path_essay, path_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "unknown_vector = np.zeros(50)\n",
    "o = np.ones(50)\n",
    "\n",
    "print(unknown_vector)\n",
    "print(unknown_vector + o + o)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
