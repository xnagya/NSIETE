{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Model trainer__\n",
    "This file contains Trainer and Statistics classes used during training of NN models. All metrics are calculated using library _torchmetrics_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassAUROC\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import net_config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, file_essay, file_missing):\n",
    "        essay_arr = np.load(file_essay)\n",
    "        indexes_arr = np.load(file_missing, allow_pickle=True)\n",
    "\n",
    "        assert (essay_arr.shape[0] == indexes_arr.shape[0]), f\"Wrong dataset size, essey count = {essay_arr.shape[0]} indexes count = {indexes_arr.shape[0]}\"\n",
    "        essey_count = essay_arr.shape[0]\n",
    "\n",
    "        self.inputs = torch.from_numpy(essay_arr).type(torch.long)\n",
    "\n",
    "        # List of tensors with target words\n",
    "        self.targets = []\n",
    "\n",
    "        # List of tensors with missing words index\n",
    "        self.missing_positions = []\n",
    "\n",
    "        # Extract missing words and their positions from numpy\n",
    "        for i in range(essey_count):\n",
    "            missing_words = []\n",
    "            missing_pos = []\n",
    "\n",
    "            for pair in indexes_arr[i]:\n",
    "                pos = pair[0]\n",
    "                word_idx = pair[1]\n",
    "\n",
    "                missing_pos.append(pos)\n",
    "                missing_words.append(word_idx)\n",
    "\n",
    "            self.missing_positions.append(torch.tensor(missing_pos, dtype=torch.long))\n",
    "            self.targets.append(torch.tensor(missing_words, dtype=torch.long))\n",
    "\n",
    "            # Set missing word count per essay\n",
    "            if (i == 0): \n",
    "                self.missing_per_essay = len(missing_words)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.inputs[idx]\n",
    "        pos = self.missing_positions[idx]\n",
    "        y = self.targets[idx]\n",
    "\n",
    "        return x, pos, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statistics:\n",
    "    def __init__(self):\n",
    "        self.metrics = dict()\n",
    "\n",
    "    def update(self, metric_name, new_value):\n",
    "        if metric_name in self.metrics:\n",
    "            values = self.metrics[metric_name]\n",
    "            values.append(new_value)\n",
    "        else:\n",
    "            values = [new_value]\n",
    "            self.metrics.update({metric_name : values})\n",
    "\n",
    "    def get_metric(self, metric_name):\n",
    "        return self.metrics.get(metric_name)\n",
    "    \n",
    "    def batch_count(self):\n",
    "        max = 0\n",
    "        for val in self.metrics.values():\n",
    "            if len(val) > max:\n",
    "                max = len(val)\n",
    "\n",
    "        return max \n",
    "    \n",
    "    def clear(self):\n",
    "        self.metrics = dict()\n",
    "\n",
    "    # First batch is 0\n",
    "    def batch_metrics(self, batch_num):\n",
    "        result = dict()\n",
    "        \n",
    "        for metric_name, values in self.metrics.items():\n",
    "            if (batch_num >= 0) and (batch_num < len(values)):\n",
    "                metric_val = values[batch_num]\n",
    "                result.update({metric_name : metric_val})\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def metric_average(self, metric_name):\n",
    "        if metric_name in self.metrics:\n",
    "            values = self.metrics[metric_name]\n",
    "            return float(sum(values) / len(values))\n",
    "        \n",
    "        else: \n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model: nn.Module, vocab_size):\n",
    "        # Select GPU device\n",
    "        self.device = (\n",
    "            \"cuda\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "\n",
    "        print(f\"Using {self.device} device for training\")\n",
    "\n",
    "        # Move model to available device\n",
    "        self.network = model.to(self.device)\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.network.parameters()\n",
    "            , lr = cfg.learning_rate\n",
    "            , betas = cfg.betas\n",
    "            , weight_decay = cfg.weight_decay\n",
    "        )\n",
    "\n",
    "        # Loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Class for saving metrics\n",
    "        self.stats = Statistics()\n",
    "\n",
    "        # Metrics \n",
    "        self.acc = MulticlassAccuracy(\n",
    "            num_classes = vocab_size\n",
    "            , average = \"weighted\"\n",
    "            )\n",
    "        self.roc = MulticlassAUROC(\n",
    "            num_classes = vocab_size\n",
    "            , average = \"weighted\"\n",
    "        )\n",
    "        self.f1 = MulticlassF1Score(\n",
    "            num_classes = vocab_size\n",
    "            , average = \"weighted\"\n",
    "        )\n",
    "\n",
    "        # Saving and loading model\n",
    "        self.best_model = None\n",
    "        self.best_accuracy = None\n",
    "\n",
    "    def load_dataset(self, essay_path, positions_path):\n",
    "        # Load dataset\n",
    "        dataset = EssayDataset(essay_path, positions_path)\n",
    "        \n",
    "        # Split dataset to train, validation and test \n",
    "        gen = torch.Generator().manual_seed(42)\n",
    "        data_train, data_val, data_test = random_split(dataset, [0.7, 0.15, 0.15], generator=gen)\n",
    "\n",
    "        # Create dataset loaders\n",
    "        self.data_train = DataLoader(data_train, batch_size = cfg.batch_size, shuffle = True)\n",
    "        self.data_val = DataLoader(data_val, batch_size = cfg.batch_size, shuffle = True)\n",
    "        self.data_test = DataLoader(data_test, batch_size = cfg.batch_size, shuffle = False)\n",
    "\n",
    "    def save_model(self, current_epoch):  \n",
    "        if self.best_model is not None:\n",
    "            checkpoint = {\n",
    "                'epoch': current_epoch,\n",
    "                'NNmodel': self.best_model.state_dict(),\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(checkpoint, cfg.model_path)\n",
    "            print(f\"NN model saved at path '{cfg.model_path}'\")\n",
    "\n",
    "    def load_model(self):\n",
    "        checkpoint = torch.load(cfg.model_path)\n",
    "\n",
    "        self.network.load_state_dict(checkpoint['NNmodel'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "        self.test_model()\n",
    "\n",
    "        print(f\"NN model loaded from path '{cfg.model_path}'\")\n",
    "        return checkpoint['epoch']\n",
    "\n",
    "    def train_model(self):\n",
    "        # Train model (dataset = data_train)\n",
    "        self.network.train()\n",
    "        start = time.time()\n",
    "\n",
    "        for x, pos, y in self.data_train:\n",
    "            x, pos, y = x.to(self.device), pos.to(self.device), y.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            x = self.network(x, pos)\n",
    "            print()\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = self.loss_fn(x.view(x.shape[0], -1), y.view(-1))\n",
    "\n",
    "            # Save batch loss\n",
    "            self.stats.update(\"loss_train\", loss)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip gradients\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm(self.network.parameters(), cfg.grad_clip)\n",
    "            self.stats.update(\"grad\", grad_norm)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"Train time in sec = {end - start}\")\n",
    "\n",
    "        # Evaulate model by calculating loss (dataset = data_val)\n",
    "        self.network.eval()\n",
    "        start = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, pos, y in self.data_val:\n",
    "                x, pos, y = x.to(self.device), pos.to(self.device), y.to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                x = self.network(x, pos)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = self.loss_fn(x.view(x.shape[0], -1), y.view(-1))\n",
    "\n",
    "                # Save batch loss\n",
    "                self.stats.update(\"loss_val\", loss)\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"Validation time in sec = {end - start}\")\n",
    "\n",
    "    # Test model by calculating metrics (dataset = data_test) and keep the best model\n",
    "    def test_model(self):\n",
    "        self.network.eval()\n",
    "        start = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, pos, y in self.data_test:\n",
    "                x, pos, y = x.to(self.device), pos.to(self.device), y.to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                x = self.network(x, pos)\n",
    "\n",
    "                classes = torch.argmax(x, dim=2)\n",
    "                confidence = torch.softmax(x, dim=2)\n",
    "                \n",
    "                torch.reshape(classes, (classes.shape[0], -1))\n",
    "                torch.reshape(confidence, (confidence.shape[0], -1))\n",
    "\n",
    "                print(classes.shape)\n",
    "                print(confidence.shape)\n",
    "\n",
    "                # Calculate metrics\n",
    "                accuracy = self.acc(classes, y).item()\n",
    "                self.stats.update(\"acc\", accuracy)\n",
    "                self.stats.update(\"f1\", self.f1(classes, y).item())\n",
    "                self.stats.update(\"auroc\", self.roc(confidence, y).item())\n",
    "                \n",
    "        end = time.time()\n",
    "        print(f\"Test time in sec = {end - start}\")\n",
    "\n",
    "        # Save best model\n",
    "        if (self.best_accuracy is None) or (self.best_accuracy < accuracy):\n",
    "            self.best_accuracy = accuracy\n",
    "            self.best_model = self.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matul\\AppData\\Local\\Temp\\ipykernel_32380\\1009245828.py:103: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  grad_norm = torch.nn.utils.clip_grad_norm(self.network.parameters(), cfg.grad_clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time in sec = 23.330018281936646\n",
      "Validation time in sec = 4.15092396736145\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1, 7054])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected `preds.shape[1]` to be equal to the number of classes but got 1 and 7054.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m t\u001b[38;5;241m.\u001b[39mload_dataset(path_essay, path_pos)\n\u001b[0;32m     12\u001b[0m t\u001b[38;5;241m.\u001b[39mtrain_model()\n\u001b[1;32m---> 13\u001b[0m t\u001b[38;5;241m.\u001b[39mtest_model()\n\u001b[0;32m     15\u001b[0m data \u001b[38;5;241m=\u001b[39m EssayDataset(path_essay, path_pos)\n\u001b[0;32m     16\u001b[0m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[1;32mIn[24], line 156\u001b[0m, in \u001b[0;36mTrainer.test_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf1(classes, y)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauroc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroc(confidence, y)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    158\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest time in sec = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torchmetrics\\metric.py:304\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_reduce_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torchmetrics\\metric.py:373\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torchmetrics\\metric.py:466\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m         update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torchmetrics\\classification\\precision_recall_curve.py:364\u001b[0m, in \u001b[0;36mMulticlassPrecisionRecallCurve.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update metric states.\"\"\"\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[1;32m--> 364\u001b[0m     _multiclass_precision_recall_curve_tensor_validation(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index)\n\u001b[0;32m    365\u001b[0m preds, target, _ \u001b[38;5;241m=\u001b[39m _multiclass_precision_recall_curve_format(\n\u001b[0;32m    366\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthresholds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m state \u001b[38;5;241m=\u001b[39m _multiclass_precision_recall_curve_update(\n\u001b[0;32m    369\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthresholds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage\n\u001b[0;32m    370\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torchmetrics\\functional\\classification\\precision_recall_curve.py:403\u001b[0m, in \u001b[0;36m_multiclass_precision_recall_curve_tensor_validation\u001b[1;34m(preds, target, num_classes, ignore_index)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `preds` to be a float tensor, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreds\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m num_classes:\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `preds.shape[1]` to be equal to the number of classes but\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    406\u001b[0m     )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m!=\u001b[39m target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected the shape of `preds` should be (N, C, ...) and the shape of `target` should be (N, ...)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreds\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected `preds.shape[1]` to be equal to the number of classes but got 1 and 7054."
     ]
    }
   ],
   "source": [
    "import models\n",
    "\n",
    "embedding_path = \"embedding_matrix.npy\"\n",
    "\n",
    "net = models.RNN(\"lstm\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "t = Trainer(net, cfg.config_NN.vocab_size)\n",
    "\n",
    "path_essay = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max50_1miss.npy\"\n",
    "path_pos = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max50_1miss.npy\"\n",
    "\n",
    "t.load_dataset(path_essay, path_pos)\n",
    "t.train_model()\n",
    "t.test_model()\n",
    "\n",
    "data = EssayDataset(path_essay, path_pos)\n",
    "data.__getitem__(50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
