{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import net_config as cfg\n",
    "from models import *\n",
    "from trainer import *\n",
    "from experiment import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"embedding_matrix.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 - different sequence lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max50_1miss.npy\"\n",
    "pos_path = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max50_1miss.npy\"\n",
    "sequence_len = 50\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max150_1miss.npy\"\n",
    "pos_path = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max150_1miss.npy\"\n",
    "sequence_len = 150\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max500_1miss.npy\"\n",
    "pos_path = r\"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max500_1miss.npy\"\n",
    "sequence_len = 500\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"RNN-{sequence_len}\"\n",
    "\n",
    "model = RNN(\"simple\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm-{sequence_len}\"\n",
    "\n",
    "model = RNN(\"lstm\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with Momentum Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatus13579\u001b[0m (\u001b[33mmteam0\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatus13579\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\wandb\\run-20240430_215147-lstm_M-50</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matus13579/NN-z3/runs/lstm_M-50' target=\"_blank\">lstm_M-50</a></strong> to <a href='https://wandb.ai/matus13579/NN-z3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matus13579/NN-z3' target=\"_blank\">https://wandb.ai/matus13579/NN-z3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matus13579/NN-z3/runs/lstm_M-50' target=\"_blank\">https://wandb.ai/matus13579/NN-z3/runs/lstm_M-50</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device for training\n"
     ]
    }
   ],
   "source": [
    "run_name = f\"lstm_M-{sequence_len}\"\n",
    "\n",
    "model = RNN(\"lstm_M\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Starting epoch 1--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\trainer.py:213: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  grad_norm = torch.nn.utils.clip_grad_norm(self.network.parameters(), cfg.grad_clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time in sec = 16.75231099128723\n",
      "Validation time in sec = 3.3684122562408447\n",
      "Test time in sec = 8.531461477279663\n",
      "--Ending epoch 1--\n",
      "--Starting epoch 2--\n",
      "Train time in sec = 18.83063578605652\n",
      "Validation time in sec = 3.5667619705200195\n",
      "Test time in sec = 9.66098165512085\n",
      "--Ending epoch 2--\n",
      "--Starting epoch 3--\n",
      "Train time in sec = 18.16631031036377\n",
      "Validation time in sec = 4.1366472244262695\n",
      "Test time in sec = 9.641722679138184\n",
      "--Ending epoch 3--\n",
      "--Starting epoch 4--\n",
      "Train time in sec = 21.0056893825531\n",
      "Validation time in sec = 4.028253555297852\n",
      "Test time in sec = 10.451473712921143\n",
      "--Ending epoch 4--\n",
      "--Starting epoch 5--\n",
      "Train time in sec = 22.12552499771118\n",
      "Validation time in sec = 3.7157936096191406\n",
      "Test time in sec = 9.902635097503662\n",
      "--Ending epoch 5--\n",
      "--Starting epoch 6--\n",
      "Train time in sec = 21.854671716690063\n",
      "Validation time in sec = 4.389939546585083\n",
      "Test time in sec = 9.917898178100586\n",
      "--Ending epoch 6--\n",
      "--Starting epoch 7--\n",
      "Train time in sec = 20.790358304977417\n",
      "Validation time in sec = 3.743177652359009\n",
      "Test time in sec = 10.095142126083374\n",
      "--Ending epoch 7--\n",
      "--Starting epoch 8--\n",
      "Train time in sec = 21.94000554084778\n",
      "Validation time in sec = 4.418291091918945\n",
      "Test time in sec = 10.265504837036133\n",
      "--Ending epoch 8--\n",
      "--Starting epoch 9--\n",
      "Train time in sec = 20.926626682281494\n",
      "Validation time in sec = 3.7383172512054443\n",
      "Test time in sec = 10.392544984817505\n",
      "--Ending epoch 9--\n",
      "--Starting epoch 10--\n",
      "Train time in sec = 23.812676906585693\n",
      "Validation time in sec = 4.3753416538238525\n",
      "Test time in sec = 12.18187403678894\n",
      "--Ending epoch 10--\n",
      "--Starting epoch 11--\n",
      "Train time in sec = 21.600184440612793\n",
      "Validation time in sec = 3.8574023246765137\n",
      "Test time in sec = 11.69471549987793\n",
      "--Ending epoch 11--\n",
      "--Starting epoch 12--\n",
      "Train time in sec = 26.03296709060669\n",
      "Validation time in sec = 4.986609935760498\n",
      "Test time in sec = 10.548990488052368\n",
      "--Ending epoch 12--\n",
      "--Starting epoch 13--\n",
      "Train time in sec = 18.73793911933899\n",
      "Validation time in sec = 3.07561993598938\n",
      "Test time in sec = 7.195549726486206\n",
      "--Ending epoch 13--\n",
      "--Starting epoch 14--\n",
      "Train time in sec = 17.45396590232849\n",
      "Validation time in sec = 3.7460198402404785\n",
      "Test time in sec = 9.839017868041992\n",
      "--Ending epoch 14--\n",
      "--Starting epoch 15--\n",
      "Train time in sec = 21.320077657699585\n",
      "Validation time in sec = 4.3144097328186035\n",
      "Test time in sec = 10.795953512191772\n",
      "--Ending epoch 15--\n",
      "--Starting epoch 16--\n",
      "Train time in sec = 16.94542169570923\n",
      "Validation time in sec = 3.6154515743255615\n",
      "Test time in sec = 8.215508460998535\n",
      "--Ending epoch 16--\n",
      "--Starting epoch 17--\n",
      "Train time in sec = 18.132436275482178\n",
      "Validation time in sec = 3.550084114074707\n",
      "Test time in sec = 8.298770666122437\n",
      "--Ending epoch 17--\n",
      "--Starting epoch 18--\n",
      "Train time in sec = 18.649389028549194\n",
      "Validation time in sec = 3.4063143730163574\n",
      "Test time in sec = 8.213908433914185\n",
      "--Ending epoch 18--\n",
      "--Starting epoch 19--\n",
      "Train time in sec = 19.29074716567993\n",
      "Validation time in sec = 3.196366310119629\n",
      "Test time in sec = 8.229787111282349\n",
      "--Ending epoch 19--\n",
      "--Starting epoch 20--\n",
      "Train time in sec = 23.08244037628174\n",
      "Validation time in sec = 4.431636810302734\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m run\u001b[38;5;241m.\u001b[39mexecute_training(epoch)\n\u001b[0;32m      2\u001b[0m run\u001b[38;5;241m.\u001b[39mstop_run()\n",
      "File \u001b[1;32mc:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\experiment.py:67\u001b[0m, in \u001b[0;36mwanDB_run.execute_training\u001b[1;34m(self, epoch_count, log_batch)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain_model()\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Test model\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtest_model()\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Log results\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_batch:\n",
      "File \u001b[1;32mc:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\trainer.py:263\u001b[0m, in \u001b[0;36mTrainer.test_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macc(classes, y)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf1(classes, y)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;66;03m# Calculating auroc takes too long - about 8x increase for test time       \u001b[39;00m\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;66;03m#self.stats.update(\"auroc\", self.roc(confidence, y).item())\u001b[39;00m\n\u001b[0;32m    267\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torchmetrics\\metric.py:304\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_reduce_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torchmetrics\\metric.py:373\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torchmetrics\\metric.py:466\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m         update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torchmetrics\\classification\\stat_scores.py:337\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    333\u001b[0m     _multiclass_stat_scores_tensor_validation(\n\u001b[0;32m    334\u001b[0m         preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[0;32m    335\u001b[0m     )\n\u001b[0;32m    336\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[1;32m--> 337\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[0;32m    338\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[0;32m    339\u001b[0m )\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state(tp, fp, tn, fn)\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torchmetrics\\functional\\classification\\stat_scores.py:409\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_update\u001b[1;34m(preds, target, num_classes, top_k, average, multidim_average, ignore_index)\u001b[0m\n\u001b[0;32m    407\u001b[0m     tp \u001b[38;5;241m=\u001b[39m confmat\u001b[38;5;241m.\u001b[39mdiag()\n\u001b[0;32m    408\u001b[0m     fp \u001b[38;5;241m=\u001b[39m confmat\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m tp\n\u001b[1;32m--> 409\u001b[0m     fn \u001b[38;5;241m=\u001b[39m confmat\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m tp\n\u001b[0;32m    410\u001b[0m     tn \u001b[38;5;241m=\u001b[39m confmat\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m-\u001b[39m (fp \u001b[38;5;241m+\u001b[39m fn \u001b[38;5;241m+\u001b[39m tp)\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tp, fp, tn, fn\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with ADAM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm_A-{sequence_len}\"\n",
    "\n",
    "model = RNN(\"lstm_A\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 - BIdirectional RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max150_1miss.npy\"\n",
    "pos_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max150_1miss.npy\"\n",
    "#sequence_len = 150\n",
    "epoch = 50\n",
    "\n",
    "cfg.config_NN.bidirectional = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN - Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"RNN-BI\"\n",
    "\n",
    "model = RNN(\"simple\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM - Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm-BI\"\n",
    "\n",
    "model = RNN(\"lstm\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with Momentum Cell - Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm_M-BI\"\n",
    "\n",
    "model = RNN(\"lstm_M\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with ADAM Cell - Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm_A-BI\"\n",
    "\n",
    "model = RNN(\"lstm_A\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3 - multiple missing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.config_NN.bidirectional = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max50_1miss.npy\"\n",
    "pos_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max50_1miss.npy\"\n",
    "sequence_len = 50\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max150_1miss.npy\"\n",
    "pos_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max150_1miss.npy\"\n",
    "sequence_len = 150\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max500_1miss.npy\"\n",
    "pos_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max500_1miss.npy\"\n",
    "sequence_len = 500\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm_M-{sequence_len}_mul\"\n",
    "\n",
    "model = RNN(\"lstm_M\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
