{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Neural network models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import abc\n",
    "from torchvision import models\n",
    "from collections import OrderedDict\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_custom(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bidirectional, drop):\n",
    "        torch.set_default_dtype(torch.float32)\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bidir = bidirectional\n",
    "        self.gates_size = (hidden_size * 2) if bidirectional else (hidden_size * 4)\n",
    "        self.eps = 1e-16\n",
    "\n",
    "        assert (self.gates_size % 4 == 0), f\"Wrong shape for lstm! Must be divisible by 4, but got {hidden_size} instead.\"\n",
    "        \n",
    "        # Network parameters\n",
    "        self.weight_ih = nn.Parameter(torch.Tensor(input_size, self.gates_size))\n",
    "        self.weight_hh = nn.Parameter(torch.Tensor(self.gates_size // 4, self.gates_size))\n",
    "        self.bias_ih = nn.Parameter(torch.Tensor(self.gates_size))\n",
    "        self.bias_hh = nn.Parameter(torch.Tensor(self.gates_size))\n",
    "\n",
    "        # Reverse network parameters\n",
    "        if bidirectional:\n",
    "            self.weight_Rih = nn.Parameter(torch.Tensor(input_size, self.gates_size))\n",
    "            self.weight_Rhh = nn.Parameter(torch.Tensor(self.gates_size // 4, self.gates_size))\n",
    "            self.bias_Rih = nn.Parameter(torch.Tensor(self.gates_size))\n",
    "            self.bias_Rhh = nn.Parameter(torch.Tensor(self.gates_size))\n",
    "        \n",
    "        # Add dropout layer\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "\n",
    "    # Forward pass for LSTM layer\n",
    "    def forward(self, input, state):\n",
    "        _ , seq_length, _ = input.shape\n",
    "        backward_state = state\n",
    "        \n",
    "        # Forward pass for each word in sequence\n",
    "        layer_output = []\n",
    "\n",
    "        for i in range(0, seq_length, 1):\n",
    "            # Get word from sequence\n",
    "            x = input[:,i,:]\n",
    "\n",
    "            # Forward pass for word\n",
    "            x, state = self.forward_cell(x, state)\n",
    "\n",
    "            # Save results \n",
    "            layer_output.append(x.unsqueeze(0))\n",
    "\n",
    "        layer_output = LSTM_custom.join_layer_output(layer_output)\n",
    "\n",
    "        # Reverse forward pass for each word in sequence\n",
    "        if self.bidir:\n",
    "            reverse_output = []\n",
    "\n",
    "            for i in range(seq_length - 1, -1, -1):\n",
    "                # Get word from sequence\n",
    "                x = input[:,i,:]\n",
    "\n",
    "                # Forward pass for word\n",
    "                x, backward_state = self.reverse_cell(x, backward_state)\n",
    "\n",
    "                # Save results \n",
    "                reverse_output.append(x.unsqueeze(0))\n",
    "            \n",
    "            reverse_output = LSTM_custom.join_layer_output(reverse_output)\n",
    "\n",
    "            # Join results from both directions\n",
    "            layer_output = torch.cat((layer_output, reverse_output), dim=2)\n",
    "            state = torch.cat((state + backward_state), dim=1)\n",
    "\n",
    "        return layer_output, state\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def initial_state(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def forward_cell(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def reverse_cell(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def join_layer_output(outputs: list[torch.Tensor]):\n",
    "        # Join results\n",
    "        t = torch.cat(outputs, dim=0)\n",
    "        # Reshape to batch_size, sequence_length, hidden_size\n",
    "        t = t.transpose(0, 1).contiguous()\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_basic(LSTM_custom):\n",
    "    def __init__(self, input_size, hidden_size, params: dict, drop = 0):\n",
    "        # Config parameters\n",
    "        try:\n",
    "            bidir = params['bidirectional']\n",
    "        except KeyError as e:\n",
    "            raise Exception(f'Parameter \"{e.args[0]}\" NOT found!')\n",
    "        \n",
    "        super().__init__(input_size, hidden_size, bidir, drop)\n",
    "        \n",
    "    def initial_state(self, batch_size):\n",
    "        h0 = torch.zeros(batch_size, self.gates_size // 4)\n",
    "        c0 = torch.zeros(batch_size, self.gates_size // 4)\n",
    "        return (h0, c0)\n",
    "    \n",
    "    # Computes forward for one timestep (one word of sequence)\n",
    "    def forward_cell(self, xt, state):\n",
    "        # Load current state \n",
    "        ht, ct = state\n",
    "\n",
    "        # Forward pass\n",
    "        gates = torch.mm(xt, self.weight_ih) + self.bias_ih + torch.mm(ht, self.weight_hh) + self.bias_hh\n",
    "\n",
    "        # Devide tensor into gates\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, dim = 1)\n",
    "\n",
    "        # Compute state of each gate\n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate = F.sigmoid(forgetgate)\n",
    "        cellgate = F.tanh(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "\n",
    "        # Compute new lstm state\n",
    "        ct = torch.mul(ct, forgetgate) +  torch.mul(ingate, cellgate)     \n",
    "        ht = torch.mul(outgate, F.tanh(ct))\n",
    "\n",
    "        # Dropout(x), state\n",
    "        return self.dropout(ht), (ht, ct)\n",
    "    \n",
    "    # Computes forward for one timestep (using reverse weights)\n",
    "    def reverse_cell(self, xt, state):\n",
    "        # Load current state \n",
    "        ht, ct = state\n",
    "\n",
    "        # Forward pass\n",
    "        gates = torch.mm(xt, self.weight_Rih) + self.bias_Rih + torch.mm(ht, self.weight_Rhh) + self.bias_Rhh\n",
    "\n",
    "        # Devide tensor into gates\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, dim = 1)\n",
    "\n",
    "        # Compute state of each gate\n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate = F.sigmoid(forgetgate)\n",
    "        cellgate = F.tanh(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "\n",
    "        # Compute new lstm state\n",
    "        ct = torch.mul(ct, forgetgate) +  torch.mul(ingate, cellgate)     \n",
    "        ht = torch.mul(outgate, F.tanh(ct))\n",
    "\n",
    "        # Dropout(x), state\n",
    "        return self.dropout(ht), (ht, ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_momentum(LSTM_custom):\n",
    "    def __init__(self, input_size, hidden_size, params: dict, drop = 0):\n",
    "        # Config parameters\n",
    "        try:\n",
    "            bidir = params['bidirectional']\n",
    "            # Momentum cell hyperparameters\n",
    "            self.mu = params['momentum']\n",
    "            self.s = params['stepsize']\n",
    "        except KeyError as e:\n",
    "            raise Exception(f'Parameter \"{e.args[0]}\" NOT found!')\n",
    "        \n",
    "        super().__init__(input_size, hidden_size, bidir, drop)\n",
    "        \n",
    "    def initial_state(self, batch_size):\n",
    "        h0 = torch.zeros(batch_size, self.gates_size // 4)\n",
    "        c0 = torch.zeros(batch_size, self.gates_size // 4)\n",
    "        v0 = torch.zeros(batch_size, self.gates_size)\n",
    "        return (h0, c0, v0)\n",
    "\n",
    "    # Computes forward for one timestep (one word of sequence)\n",
    "    def forward_cell(self, xt, state):\n",
    "        # Load current state \n",
    "        ht, ct, vt = state\n",
    "\n",
    "        # Forward pass\n",
    "        vt = self.mu * vt + self.s * (torch.mm(xt, self.weight_ih) + self.bias_ih)\n",
    "        gates = vt + torch.mm(ht, self.weight_hh) + self.bias_hh\n",
    "        #print(f\"gates = {gates.shape}\")\n",
    "\n",
    "        # Devide tensor into gates\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, dim = 1)\n",
    "\n",
    "        # Compute state of each gate\n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate = F.sigmoid(forgetgate)\n",
    "        cellgate = F.tanh(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "\n",
    "        # Compute new lstm state\n",
    "        ct = torch.mul(ct, forgetgate) +  torch.mul(ingate, cellgate)     \n",
    "        ht = torch.mul(outgate, F.tanh(ct))\n",
    "\n",
    "        # Dropout(x), state\n",
    "        return self.dropout(ht), (ht, ct, vt)\n",
    "    \n",
    "    # Computes forward for one timestep (using reverse weights)\n",
    "    def reverse_cell(self, xt, state):\n",
    "        # Load current state \n",
    "        ht, ct, vt = state\n",
    "\n",
    "        # Forward pass\n",
    "        vt = self.mu * vt + self.s * (torch.mm(xt, self.weight_Rih) + self.bias_Rih)\n",
    "        gates = vt + torch.mm(ht, self.weight_Rhh) + self.bias_Rhh\n",
    "        #print(f\"gates = {gates.shape}\")\n",
    "\n",
    "        # Devide tensor into gates\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, dim = 1)\n",
    "\n",
    "        # Compute state of each gate\n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate = F.sigmoid(forgetgate)\n",
    "        cellgate = F.tanh(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "\n",
    "        # Compute new lstm state\n",
    "        ct = torch.mul(ct, forgetgate) +  torch.mul(ingate, cellgate)     \n",
    "        ht = torch.mul(outgate, F.tanh(ct))\n",
    "\n",
    "        # Dropout(x), state\n",
    "        return self.dropout(ht), (ht, ct, vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_adam(LSTM_custom):\n",
    "    def __init__(self, input_size, hidden_size, params: dict, drop = 0):\n",
    "        # Config parameters\n",
    "        try:\n",
    "            bidir = params['bidirectional']\n",
    "            # Adam cell hyperparameters\n",
    "            self.mu = params['momentum']\n",
    "            self.s = params['stepsize']\n",
    "            self.b = params['rnn_beta']\n",
    "        except KeyError as e:\n",
    "            raise Exception(f'Parameter \"{e.args[0]}\" NOT found!')\n",
    "        \n",
    "        super().__init__(input_size, hidden_size, bidir, drop)\n",
    "        \n",
    "    def initial_state(self, batch_size):\n",
    "        h0 = torch.zeros(batch_size, self.gates_size // 4)\n",
    "        c0 = torch.zeros(batch_size, self.gates_size // 4)\n",
    "        v0 = torch.zeros(batch_size, self.gates_size)\n",
    "        m0 = torch.zeros(batch_size, self.gates_size)\n",
    "        return (h0, c0, v0, m0)\n",
    "\n",
    "    # Computes forward for one timestep (one word of sequence)\n",
    "    def forward_cell(self, xt, state):\n",
    "        # Load current state \n",
    "        ht, ct, vt, mt = state\n",
    "\n",
    "        # Forward pass\n",
    "        grad = torch.mm(xt, self.weight_ih) + self.bias_ih\n",
    "        vt = self.mu * vt + self.s * grad\n",
    "        mt = self.b * mt + (1 - self.b) * (grad * grad)\n",
    "        gates = (vt / (torch.sqrt(mt) + self.eps)) + torch.mm(ht, self.weight_hh) + self.bias_hh\n",
    "        #print(f\"gates = {gates.shape}\")\n",
    "\n",
    "        # Devide tensor into gates\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, dim = 1)\n",
    "\n",
    "        # Compute state of each gate\n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate = F.sigmoid(forgetgate)\n",
    "        cellgate = F.tanh(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "\n",
    "        # Compute new lstm state\n",
    "        ct = torch.mul(ct, forgetgate) +  torch.mul(ingate, cellgate)     \n",
    "        ht = torch.mul(outgate, F.tanh(ct))\n",
    "\n",
    "        # Dropout(x), state\n",
    "        return self.dropout(ht), (ht, ct, vt, mt)\n",
    "    \n",
    "    # Computes forward for one timestep (using reverse weights)\n",
    "    def reverse_cell(self, xt, state):\n",
    "        # Load current state \n",
    "        ht, ct, vt, mt = state\n",
    "\n",
    "        # Forward pass\n",
    "        grad = torch.mm(xt, self.weight_Rih) + self.bias_Rih\n",
    "        vt = self.mu * vt + self.s * grad\n",
    "        mt = self.b * mt + (1 - self.b) * (grad * grad)\n",
    "        gates = (vt / (torch.sqrt(mt) + self.eps)) + torch.mm(ht, self.weight_Rhh) + self.bias_Rhh\n",
    "        #print(f\"gates = {gates.shape}\")\n",
    "\n",
    "        # Devide tensor into gates\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, dim = 1)\n",
    "\n",
    "        # Compute state of each gate\n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate = F.sigmoid(forgetgate)\n",
    "        cellgate = F.tanh(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "\n",
    "        # Compute new lstm state\n",
    "        ct = torch.mul(ct, forgetgate) +  torch.mul(ingate, cellgate)     \n",
    "        ht = torch.mul(outgate, F.tanh(ct))\n",
    "\n",
    "        # Dropout(x), state\n",
    "        return self.dropout(ht), (ht, ct, vt, mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_RNNtypes = [\"simple\", \"lstm\", \"lstm_M\", \"lstm_A\"]\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, rnn_type, vocabulary_size, params: dict):\n",
    "        torch.set_default_dtype(torch.float32)\n",
    "        super().__init__()\n",
    "\n",
    "        assert rnn_type in ALL_RNNtypes, f\"RNN type '{rnn_type} 'is NOT supported.\"\n",
    "        self.rnn_type = rnn_type\n",
    "\n",
    "        # Config parameters\n",
    "        try:\n",
    "            # Embedding layer\n",
    "            drop_embed = params['embedding_dropout']\n",
    "            pad_idx = params['padding_index']\n",
    "            embedding_dims = params['embedding_features']\n",
    "            file_path = params['embedding_file']\n",
    "\n",
    "            # RNN layer\n",
    "            self.layer_count = params['rnn_layers']\n",
    "            drop_rnn = params['rnn_dropout'] \n",
    "            hidden_size = params['hidden_features']\n",
    "            bidir = params['bidirectional']\n",
    "        except KeyError as e:\n",
    "            raise Exception(f'Parameter \"{e.args[0]}\" NOT found!')\n",
    "        \n",
    "        # Encoder layer = encodes indices of words to embedding vectors\n",
    "        \"\"\"\"\n",
    "        self.encoder = nn.Embedding.from_pretrained (\n",
    "            embeddings = torch.load(file_path), \n",
    "            freeze= True, \n",
    "            padding_idx = pad_idx\n",
    "            )\n",
    "            \n",
    "        \"\"\"\n",
    "        self.encoder = nn.Embedding(\n",
    "            num_embeddings = vocabulary_size\n",
    "            , embedding_dim = embedding_dims\n",
    "            , padding_idx = pad_idx\n",
    "            )\n",
    "\n",
    "\n",
    "        # Dropout layer -> drops embedding features\n",
    "        self.dropout = nn.Dropout(drop_embed)\n",
    "\n",
    "        # Initialize RNN layers\n",
    "        self.rnns = nn.ModuleList()\n",
    "\n",
    "        match self.rnn_type:\n",
    "            # RNN - built_in\n",
    "            case \"simple\":\n",
    "                # Reduce hidden_size if bidirectional\n",
    "                output_size = (hidden_size // 2) if bidir else hidden_size\n",
    "\n",
    "                self.rnns.append(nn.RNN(\n",
    "                    input_size = embedding_dims, \n",
    "                    hidden_size = output_size, \n",
    "                    num_layers = self.layer_count, \n",
    "                    bidirectional = bidir,\n",
    "                    dropout = drop_rnn, \n",
    "                    batch_first = True\n",
    "                ))\n",
    "\n",
    "            # LSTM\n",
    "            case \"lstm\":\n",
    "                for i in range(self.layer_count):\n",
    "                    # First layer\n",
    "                    if (i == 0):\n",
    "                        self.rnns.append(LSTM_basic(embedding_dims, hidden_size, params, drop_rnn))\n",
    "                    # Last layer, no dropout\n",
    "                    elif (i == self.layer_count - 1):\n",
    "                        self.rnns.append(LSTM_basic(hidden_size, hidden_size, params))\n",
    "                    # Other layers\n",
    "                    else:\n",
    "                        self.rnns.append(LSTM_basic(hidden_size, hidden_size, params, drop_rnn))               \n",
    "\n",
    "            # LSTM - momentum\n",
    "            case \"lstm_M\":\n",
    "                for i in range(self.layer_count):\n",
    "                    # First layer\n",
    "                    if (i == 0):\n",
    "                        self.rnns.append(LSTM_momentum(embedding_dims, hidden_size, params, drop_rnn))\n",
    "                    # Last layer, no dropout\n",
    "                    elif (i == self.layer_count - 1):\n",
    "                        self.rnns.append(LSTM_momentum(hidden_size, hidden_size, params))\n",
    "                    # Other layers\n",
    "                    else:\n",
    "                        self.rnns.append(LSTM_momentum(hidden_size, hidden_size, params, drop_rnn))    \n",
    "\n",
    "            # LSTM - momentum ADAM\n",
    "            case \"lstm_A\":\n",
    "                for i in range(self.layer_count):\n",
    "                    # First layer\n",
    "                    if (i == 0):\n",
    "                        self.rnns.append(LSTM_adam(embedding_dims, hidden_size, params, drop_rnn))\n",
    "                    # Last layer, no dropout\n",
    "                    elif (i == self.layer_count - 1):\n",
    "                        self.rnns.append(LSTM_adam(hidden_size, hidden_size, params))\n",
    "                    # Other layers\n",
    "                    else:\n",
    "                        self.rnns.append(LSTM_adam(hidden_size, hidden_size, params, drop_rnn))    \n",
    "\n",
    "        # Decoder layer = output layer for network\n",
    "        self.decoder = nn.Linear(hidden_size, vocabulary_size)\n",
    "\n",
    "        # Initialize network weights (embedding is pretrained)\n",
    "        self.init_weights()\n",
    "                 \n",
    "    def init_weights(self):\n",
    "        for model in self.rnns:\n",
    "            for name, par in model.named_parameters(): \n",
    "                # Initialize weights\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(par)\n",
    "\n",
    "                # Initialize bias\n",
    "                elif 'bias' in name:\n",
    "                    par.data.fill_(0)\n",
    "\n",
    "        # Output layer initialization\n",
    "        for name, par in self.decoder.named_parameters():\n",
    "            # Initialize weights\n",
    "            # TODO change weight init\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(par)\n",
    "\n",
    "            # Initialize bias\n",
    "            elif 'bias' in name:\n",
    "                par.data.fill_(0)\n",
    "\n",
    "    # Remove zeroes (padding) from tensor\n",
    "    # t.shape = (batch_size, sequence_length)\n",
    "    def reduce_tensor(t: torch.tensor):\n",
    "        zeros_count = (t == 0.).sum(dim=1)\n",
    "        print(zeros_count)\n",
    "        lowest_count = torch.min(zeros_count)\n",
    "\n",
    "        new_length = t.shape[1] - lowest_count\n",
    "        return t[:,0 : new_length]\n",
    "\n",
    "    # Input shape = (batch_size, sequence_length)\n",
    "    def forward(self, input, indexes: tuple):\n",
    "        # Reduce input sequence length\n",
    "        input = RNN.reduce_tensor(input)\n",
    "\n",
    "        batch_size, sequence_length  = input.shape\n",
    "\n",
    "        for n in indexes:\n",
    "            assert n < sequence_length, f\"Wrong index '{n}' for input with length {sequence_length}.\"\n",
    "\n",
    "        # Embedding \n",
    "        input = self.encoder(input)\n",
    "\n",
    "        # Dropout \n",
    "        input = self.dropout(input)\n",
    "\n",
    "        # Clear layer states\n",
    "        self.states = []\n",
    "\n",
    "        if (self.rnn_type != \"simple\"):\n",
    "            self.state = []\n",
    "\n",
    "            # Initiate layer states\n",
    "            for layer in self.rnns:\n",
    "                self.state.append(layer.initial_state(batch_size))\n",
    "\n",
    "            # Compute RNN forward for each layer\n",
    "            for i, layer in enumerate(self.rnns):\n",
    "                #print(lstm)\n",
    "                current_state = self.state[i]\n",
    "                input, current_state = layer.forward(input, current_state)\n",
    "                self.state[i] = current_state\n",
    "        else:\n",
    "            # Initiate rnn state\n",
    "            self.state = None\n",
    "\n",
    "            for layer in self.rnns:\n",
    "                input, self.state = layer.forward(input, self.state)\n",
    "\n",
    "        # Extract missing words based od indexes\n",
    "        input = input[:,indexes,:]\n",
    "\n",
    "        # Create output with linear layer\n",
    "        return self.decoder(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE = torch.Size([8, 10])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0])\n",
      "OUTPUT SHAPE = torch.Size([8, 2, 100])\n"
     ]
    }
   ],
   "source": [
    "from net_config import *\n",
    "\n",
    "vocab_size = 100\n",
    "\n",
    "# Input tensor\n",
    "batch_size = 8\n",
    "seq_length = 10\n",
    "\n",
    "test_input = torch.randint(0, vocab_size, (batch_size, seq_length))\n",
    "print(f\"INPUT SHAPE = {test_input.shape}\")\n",
    "\n",
    "#print(test_input)\n",
    "\n",
    "net = RNN(\"lstm\", vocab_size, config_to_dict(config_NN))\n",
    "\n",
    "output = net.forward(test_input, (0, 9))\n",
    "print(f\"OUTPUT SHAPE = {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARDMAX SHAPE = torch.Size([8, 2])\n",
      "tensor([[73, 96],\n",
      "        [45, 61],\n",
      "        [14, 95],\n",
      "        [73,  6],\n",
      "        [90, 80],\n",
      "        [45, 57],\n",
      "        [92, 61],\n",
      "        [86, 86]])\n"
     ]
    }
   ],
   "source": [
    "output = torch.argmax(output, dim=2)\n",
    "print(f\"HARDMAX SHAPE = {output.shape}\")\n",
    "print(output)\n",
    "\n",
    "# TODO - extract hardmax index for missing word\n",
    "# TODO - look at SOFTMAX for metrics ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
