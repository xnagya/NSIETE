{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __WanDB Experiment__\n",
    "This file connects _models.py_ and _trainer.py_ files and manages experiments created in wanDB. It also contains dataset reresentation as Dataset subclass (Lizard_dataset). Experiments are defined in file NN-z2 (main file).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import net_config as cfg\n",
    "from models import *\n",
    "#from trainer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wanDB run class\n",
    "\n",
    "This class executes training epochs by calling trainer functions. It also logs metrics and decides when the model params are saved (locally).\n",
    "This class contains: \n",
    "- Current wanDB run \n",
    "- Trainer\n",
    "- Save interval (every n-th epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wanDB_run: \n",
    "    def __init__(self, run_name, run_id, model: nn.Module, save_interval = None):\n",
    "        wandb.login()\n",
    "        \n",
    "        wandb.finish()\n",
    "        \n",
    "        self.run = wandb.init(\n",
    "        entity = cfg.project_entity, \n",
    "        project = cfg.project_name,     \n",
    "        name = run_name, \n",
    "        id = run_id\n",
    "        )\n",
    "\n",
    "        wandb.config = cfg.config_to_dict(cfg.config_Unet)\n",
    "\n",
    "        self.trainer = Trainer(model)\n",
    "        self.save_interval = save_interval\n",
    "        self.datasets_loaded = False\n",
    "        self.batch_count = 0\n",
    "\n",
    "        # Load best model\n",
    "        if (self.save_interval is not None) and os.path.isfile(cfg.model_path):\n",
    "            self.current_epoch = self.trainer.load_model()\n",
    "        else:\n",
    "            self.current_epoch = 0\n",
    "\n",
    "    def load_datasets(self, essay_path, positions_path):\n",
    "        self.trainer.load_dataset(essay_path, positions_path)\n",
    "        self.datasets_loaded = True\n",
    "    \n",
    "    def execute_training(self, epoch_count, log_batch = False):\n",
    "        assert self.datasets_loaded, \"Datasets are NOT loaded\"\n",
    "\n",
    "        for _ in range(epoch_count):\n",
    "            self.current_epoch += 1\n",
    "            print(f\"--Starting epoch {self.current_epoch}--\")\n",
    "\n",
    "            # Train model\n",
    "            self.trainer.train_model()\n",
    "            # Test model\n",
    "            self.trainer.test_model()\n",
    "            \n",
    "            # Log results\n",
    "            if log_batch:\n",
    "                for i in range(self.trainer.stats.batch_count()):\n",
    "                    self.batch_count += 1\n",
    "                    batch_metrics = self.trainer.stats.batch_metrics(i)\n",
    "\n",
    "                    self.run.log({\"loss_train\": batch_metrics.get(\"loss_train\"), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"loss_val\": batch_metrics.get(\"loss_val\"), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"accuracy\": batch_metrics.get(\"acc\"), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"f1_score\": batch_metrics.get(\"f1\"), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"auroc\": batch_metrics.get(\"auroc\"), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"grad\": batch_metrics.get(\"grad\"), \"batch\": self.batch_count})\n",
    "            else:\n",
    "                # Get metrics average\n",
    "                tl = self.trainer.stats.metric_average(\"loss_train\")\n",
    "                vl = self.trainer.stats.metric_average(\"loss_val\")\n",
    "                acc = self.trainer.stats.metric_average(\"accuracy\")\n",
    "                f1 = self.trainer.stats.metric_average(\"f1_score\")\n",
    "                roc = self.trainer.stats.metric_average(\"auroc\")\n",
    "                g = self.trainer.stats.metric_average(\"grad\")\n",
    "\n",
    "                # Save metrics to wandb\n",
    "                self.run.log({\"loss_train\": tl, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"loss_val\": vl, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"accuracy\": acc, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"f1_score\": f1, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"auroc\": roc, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"grad\": roc, \"epoch\": self.current_epoch})\n",
    "\n",
    "            self.trainer.stats.clear()\n",
    "            gc.collect()\n",
    "\n",
    "            # Save best model\n",
    "            if (self.save_interval is not None) and (self.current_epoch % self.save_interval == 0):\n",
    "                self.trainer.save_model(self.current_epoch)\n",
    "\n",
    "            print(f\"--Ending epoch {self.current_epoch}--\")\n",
    "    \n",
    "    def stop_run(self):\n",
    "        self.run.finish()\n",
    "        del self.trainer\n",
    "        self.datasets_loaded = False\n",
    "\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"embedding_matrix.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 - different sequence lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max50_1miss.npy\"\n",
    "pos_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max50_1miss.npy\"\n",
    "sequence_len = 50\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max150_1miss.npy\"\n",
    "pos_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max150_1miss.npy\"\n",
    "sequence_len = 150\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max500_1miss.npy\"\n",
    "pos_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max500_1miss.npy\"\n",
    "sequence_len = 500\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"RNN-{sequence_len}\"\n",
    "\n",
    "model = RNN(\"simple\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm-{sequence_len}\"\n",
    "\n",
    "model = RNN(\"lstm\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with Momentum Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm_M-{sequence_len}\"\n",
    "\n",
    "model = RNN(\"lstm_M\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with ADAM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm_A-{sequence_len}\"\n",
    "\n",
    "model = RNN(\"lstm_A\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 - BIdirectional RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max150_1miss.npy\"\n",
    "pos_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max150_1miss.npy\"\n",
    "#sequence_len = 150\n",
    "epoch = 50\n",
    "\n",
    "cfg.config_NN.bidirectional = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN - Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"RNN-BI\"\n",
    "\n",
    "model = RNN(\"simple\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM - Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm-BI\"\n",
    "\n",
    "model = RNN(\"lstm\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with Momentum Cell - Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm_M-BI\"\n",
    "\n",
    "model = RNN(\"lstm_M\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with ADAM Cell - Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm_A-BI\"\n",
    "\n",
    "model = RNN(\"lstm_A\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3 - multiple missing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.config_NN.bidirectional = True # or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max50_1miss.npy\"\n",
    "pos_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max50_1miss.npy\"\n",
    "sequence_len = 50\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max150_1miss.npy\"\n",
    "pos_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max150_1miss.npy\"\n",
    "sequence_len = 150\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\essays_tensor_representation_max500_1miss.npy\"\n",
    "pos_path = \"C:\\Users\\matul\\Desktop\\NSIETE\\zadanie3\\output\\position_index_pairs_max500_1miss.npy\"\n",
    "sequence_len = 500\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"lstm_M-{sequence_len}_mul\"\n",
    "\n",
    "model = RNN(\"lstm_M\", embedding_path, cfg.config_to_dict(cfg.config_NN))\n",
    "run = wanDB_run(run_name, run_name, model)\n",
    "run.load_datasets(essay_path, pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execute_training(epoch)\n",
    "run.stop_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
