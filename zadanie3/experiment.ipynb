{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __WanDB Experiment__\n",
    "This file connects _models.py_ and _trainer.py_ files and manages experiments created in wanDB. It also contains dataset reresentation as Dataset subclass (Lizard_dataset). Experiments are defined in file NN-z2 (main file).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import net_config as cfg\n",
    "#from models import *\n",
    "#from trainer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wanDB run class\n",
    "\n",
    "This class executes training epochs by calling trainer functions. It also logs metrics and decides when the model params are saved (locally).\n",
    "This class contains: \n",
    "- Current wanDB run \n",
    "- Trainer\n",
    "- Save interval (every n-th epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wanDB_run: \n",
    "    def __init__(self, run_name, run_id, model: nn.Module, save_interval = None):\n",
    "        wandb.login()\n",
    "        \n",
    "        wandb.finish()\n",
    "        \n",
    "        self.run = wandb.init(\n",
    "        entity = cfg.project_entity, \n",
    "        project = cfg.project_name,     \n",
    "        name = run_name, \n",
    "        id = run_id\n",
    "        )\n",
    "\n",
    "        wandb.config = cfg.config_to_dict(cfg.config_Unet)\n",
    "\n",
    "        self.trainer = Trainer(model)\n",
    "        self.save_interval = save_interval\n",
    "        self.datasets_loaded = False\n",
    "        self.batch_count = 0\n",
    "\n",
    "        # Load best model\n",
    "        if (self.save_interval is not None) and os.path.isfile(cfg.model_path):\n",
    "            self.current_epoch = self.trainer.load_model()\n",
    "        else:\n",
    "            self.current_epoch = 0\n",
    "\n",
    "    def load_datasets(self, train_pathX, train_pathY, val_pathX, val_pathY, test_pathX, test_pathY):\n",
    "        #self.trainer.load_dataset(trainData, valData, testData)\n",
    "        self.datasets_loaded = True\n",
    "\n",
    "    \n",
    "    def execute_training(self, epoch_count, log_batch = False):\n",
    "        assert self.datasets_loaded, \"Datasets are NOT loaded\"\n",
    "\n",
    "        for _ in range(epoch_count):\n",
    "            self.current_epoch += 1\n",
    "            print(f\"--Starting epoch {self.current_epoch}--\")\n",
    "\n",
    "            # Train model\n",
    "            self.trainer.train_model()\n",
    "            # Evaluate model\n",
    "            self.trainer.evaluate_model()\n",
    "\n",
    "            if log_batch:\n",
    "                for i in range(self.trainer.stats.batch_count()):\n",
    "                    self.batch_count += 1\n",
    "                    m = self.trainer.stats.batch_metrics(i)\n",
    "\n",
    "                    self.run.log({\"loss_train\": m.get(cfg.metric_name_Tloss), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"loss_val\": m.get(cfg.metric_name_Vloss), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"accuracy\": m.get(cfg.metric_name_acc), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"iou\": m.get(cfg.metric_name_iou), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"dice\": m.get(cfg.metric_name_dice), \"batch\": self.batch_count})\n",
    "\n",
    "            \n",
    "            else:\n",
    "                # Get metrics average\n",
    "                tl = self.trainer.stats.metric_average(cfg.metric_name_Tloss)\n",
    "                vl = self.trainer.stats.metric_average(cfg.metric_name_Vloss)\n",
    "                acc = self.trainer.stats.metric_average(cfg.metric_name_acc)\n",
    "                iou = self.trainer.stats.metric_average(cfg.metric_name_iou)\n",
    "                dice = self.trainer.stats.metric_average(cfg.metric_name_dice)\n",
    "\n",
    "                # Save metrics to wandb\n",
    "                self.run.log({\"loss_train\": tl, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"loss_val\": vl, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"accuracy\": acc, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"iou\": iou, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"dice\": dice, \"epoch\": self.current_epoch})\n",
    "\n",
    "            self.trainer.stats.clear()\n",
    "            gc.collect()\n",
    "\n",
    "            # Save best model\n",
    "            if (self.save_interval is not None) and (self.current_epoch % self.save_interval == 0):\n",
    "                self.trainer.save_model(self.current_epoch)\n",
    "\n",
    "            print(f\"--Ending epoch {self.current_epoch}--\")\n",
    "    \n",
    "    def stop_run(self):\n",
    "        self.run.finish()\n",
    "        del self.trainer\n",
    "        self.datasets_loaded = False\n",
    "\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'net_config' has no attribute 'config_Unet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m d \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mconfig_to_dict(cfg\u001b[38;5;241m.\u001b[39mconfig_Unet)\n\u001b[0;32m      4\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(t\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'net_config' has no attribute 'config_Unet'"
     ]
    }
   ],
   "source": [
    "d = cfg.config_to_dict(cfg.config_Unet)\n",
    "\n",
    "\n",
    "t = torch.rand(14, 3, 500, 500)\n",
    "print(t.shape)\n",
    "\n",
    "t = net(t)\n",
    "print(t.shape)\n",
    "\n",
    "classes = torch.argmax(t, dim = 1)\n",
    "print(classes.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
