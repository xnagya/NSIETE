{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __WanDB Experiment__\n",
    "This file connects _models.py_ and _trainer.py_ files and manages experiments created in wanDB. Experiments are defined in NN_z3.ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import net_config as cfg\n",
    "from models import *\n",
    "from trainer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wanDB run class\n",
    "\n",
    "This class executes training epochs by calling trainer functions. It also logs metrics and decides when the model params are saved (locally).\n",
    "This class contains: \n",
    "- Current wanDB run \n",
    "- Trainer\n",
    "- Save interval (every n-th epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wanDB_run: \n",
    "    def __init__(self, run_name, run_id, model: nn.Module, save_interval = None):\n",
    "        wandb.login()\n",
    "        \n",
    "        #wandb.finish()\n",
    "        \n",
    "        self.run = wandb.init(\n",
    "        entity = cfg.project_entity, \n",
    "        project = cfg.project_name,     \n",
    "        name = run_name, \n",
    "        id = run_id, \n",
    "        settings = wandb.Settings(start_method=\"fork\")\n",
    "        )\n",
    "\n",
    "        wandb.config = cfg.config_to_dict(cfg.config_NN)\n",
    "\n",
    "        self.trainer = Trainer(model, cfg.config_NN.vocab_size)\n",
    "        self.save_interval = save_interval\n",
    "        self.datasets_loaded = False\n",
    "        self.batch_count = 0\n",
    "\n",
    "        # Load best model\n",
    "        if (self.save_interval is not None) and os.path.isfile(cfg.model_path):\n",
    "            self.current_epoch = self.trainer.load_model()\n",
    "        else:\n",
    "            self.current_epoch = 0\n",
    "\n",
    "    def load_datasets(self, essay_path, positions_path):\n",
    "        self.trainer.load_dataset(essay_path, positions_path)\n",
    "        self.datasets_loaded = True\n",
    "    \n",
    "    def execute_training(self, epoch_count, log_batch = False):\n",
    "        assert self.datasets_loaded, \"Datasets are NOT loaded\"\n",
    "\n",
    "        for _ in range(epoch_count):\n",
    "            self.current_epoch += 1\n",
    "            print(f\"--Starting epoch {self.current_epoch}--\")\n",
    "\n",
    "            # Train model\n",
    "            self.trainer.train_model()\n",
    "            # Test model\n",
    "            self.trainer.test_model()\n",
    "            \n",
    "            # Log results\n",
    "            if log_batch:\n",
    "                for i in range(self.trainer.stats.batch_count()):\n",
    "                    self.batch_count += 1\n",
    "                    batch_metrics = self.trainer.stats.batch_metrics(i)\n",
    "\n",
    "                    self.run.log({\"loss_train\": batch_metrics.get(\"loss_train\"), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"loss_val\": batch_metrics.get(\"loss_val\"), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"accuracy\": batch_metrics.get(\"acc\"), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"f1_score\": batch_metrics.get(\"f1\"), \"batch\": self.batch_count})\n",
    "                    #self.run.log({\"auroc\": batch_metrics.get(\"auroc\"), \"batch\": self.batch_count})\n",
    "                    self.run.log({\"grad\": batch_metrics.get(\"grad\"), \"batch\": self.batch_count})\n",
    "            else:\n",
    "                # Get metrics average\n",
    "                tl = self.trainer.stats.metric_average(\"loss_train\")\n",
    "                vl = self.trainer.stats.metric_average(\"loss_val\")\n",
    "                acc = self.trainer.stats.metric_average(\"acc\")\n",
    "                f1 = self.trainer.stats.metric_average(\"f1\")\n",
    "                #roc = self.trainer.stats.metric_average(\"auroc\")\n",
    "                g = self.trainer.stats.metric_average(\"grad\")\n",
    "\n",
    "                # Save metrics to wandb\n",
    "                self.run.log({\"loss_train\": tl, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"loss_val\": vl, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"accuracy\": acc, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"f1_score\": f1, \"epoch\": self.current_epoch})\n",
    "                #self.run.log({\"auroc\": roc, \"epoch\": self.current_epoch})\n",
    "                self.run.log({\"grad\": g, \"epoch\": self.current_epoch})\n",
    "\n",
    "            self.trainer.stats.clear()\n",
    "            gc.collect()\n",
    "\n",
    "            # Save best model\n",
    "            if (self.save_interval is not None) and (self.current_epoch % self.save_interval == 0):\n",
    "                self.trainer.save_model(self.current_epoch)\n",
    "\n",
    "            print(f\"--Ending epoch {self.current_epoch}--\")\n",
    "    \n",
    "    def stop_run(self):\n",
    "        self.run.finish()\n",
    "        del self.trainer\n",
    "        self.datasets_loaded = False\n",
    "\n",
    "        gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
