{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Predicting cell biological response__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run other .ipybn files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         D1        D2    D3   D4        D5        D6        D7        D8  \\\n",
      "0  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166  0.585445   \n",
      "1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105  0.411754   \n",
      "2  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453  0.517720   \n",
      "3  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606  0.288764   \n",
      "4  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361  0.303809   \n",
      "\n",
      "         D9       D10  ...  D1768  D1769  D1770  D1771  D1772  D1773  D1774  \\\n",
      "0  0.743663  0.243144  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1  0.836582  0.106480  ...    1.0    1.0    1.0    0.0    1.0    0.0    0.0   \n",
      "2  0.679051  0.352308  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3  0.805110  0.208989  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4  0.812646  0.125177  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   D1775  D1776  target  \n",
      "0    0.0    0.0       1  \n",
      "1    1.0    0.0       1  \n",
      "2    0.0    0.0       1  \n",
      "3    0.0    0.0       1  \n",
      "4    0.0    0.0       0  \n",
      "\n",
      "[5 rows x 1777 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3751 entries, 0 to 3750\n",
      "Columns: 1777 entries, D1 to target\n",
      "dtypes: float64(1776), int64(1)\n",
      "memory usage: 50.9 MB\n",
      "None\n",
      "                D1           D2           D3           D4           D5  \\\n",
      "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
      "mean      0.076948     0.592436     0.068142     0.038990     0.212112   \n",
      "std       0.079989     0.105860     0.078414     0.115885     0.102592   \n",
      "min       0.000000     0.282128     0.000000     0.000000     0.002630   \n",
      "25%       0.033300     0.517811     0.000000     0.000000     0.138118   \n",
      "50%       0.066700     0.585989     0.050000     0.000000     0.190926   \n",
      "75%       0.100000     0.668395     0.100000     0.000000     0.261726   \n",
      "max       1.000000     0.964381     0.950000     1.000000     1.000000   \n",
      "\n",
      "                D6           D7           D8           D9          D10  ...  \\\n",
      "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000  ...   \n",
      "mean      0.686653     0.274713     0.455133     0.749517     0.270411  ...   \n",
      "std       0.078702     0.090017     0.162731     0.071702     0.096128  ...   \n",
      "min       0.137873     0.006130     0.000000     0.275590     0.003040  ...   \n",
      "25%       0.625627     0.207374     0.378062     0.707339     0.194357  ...   \n",
      "50%       0.674037     0.277845     0.499942     0.738961     0.284316  ...   \n",
      "75%       0.740663     0.335816     0.569962     0.788177     0.344626  ...   \n",
      "max       0.994735     0.790831     0.989870     1.000000     1.000000  ...   \n",
      "\n",
      "             D1768        D1769        D1770        D1771        D1772  \\\n",
      "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
      "mean      0.014663     0.013863     0.021861     0.015196     0.016796   \n",
      "std       0.120215     0.116938     0.146249     0.122348     0.128522   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "             D1773        D1774        D1775        D1776       target  \n",
      "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000  \n",
      "mean      0.012263     0.011730     0.020261     0.011197     0.542255  \n",
      "std       0.110074     0.107683     0.140911     0.105236     0.498278  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       0.000000     0.000000     0.000000     0.000000     1.000000  \n",
      "75%       0.000000     0.000000     0.000000     0.000000     1.000000  \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "\n",
      "[8 rows x 1777 columns]\n",
      "D1        float64\n",
      "D2        float64\n",
      "D3        float64\n",
      "D4        float64\n",
      "D5        float64\n",
      "           ...   \n",
      "D1773     float64\n",
      "D1774     float64\n",
      "D1775     float64\n",
      "D1776     float64\n",
      "target      int64\n",
      "Length: 1777, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# %run NN_model.ipynb\n",
    "from NN_model import *\n",
    "\n",
    "%run NN_dataset.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset representation for NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, normalize: bool):\n",
    "        # Save predictors as DataFrame\n",
    "        self.cell_descriptors = data.drop(columns=['target'])\n",
    "        res = data['target']\n",
    "\n",
    "        #if normalize:\n",
    "            #res = res.apply(lambda x: -1 if x == 0 else 1)\n",
    "\n",
    "        # Save target as DataFrame\n",
    "        self.cell_response = res.astype('float64').to_frame()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cell_descriptors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        desc = self.cell_descriptors.iloc[idx]\n",
    "        res = self.cell_response.iloc[idx]\n",
    "        return desc.values, res.values\n",
    "    \n",
    "    def get_input_size(self):\n",
    "        return self.cell_descriptors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wandb Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"NN-z1\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e0269a911c4ee98753cf401c8271a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011277777777932999, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: c:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py 854 getcaller\n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "Run initialization has timed out after 90.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlogin()\n\u001b[0;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_NOTEBOOK_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNN-z1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m run \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39minit(\n\u001b[0;32m      6\u001b[0m     entity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatus13579\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m#dont change\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     project \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNN-z1\u001b[39m\u001b[38;5;124m\"\u001b[39m,      \u001b[38;5;66;03m#dont change\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu_test\u001b[39m\u001b[38;5;124m\"\u001b[39m       \u001b[38;5;66;03m#run name\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#id =                   #define run with ID (used for resuming)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m#resume = True           #resume run\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#show graphs in Jupyter Notebook\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#%%wandb                   \u001b[39;00m\n\u001b[0;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:1195\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:1176\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1174\u001b[0m except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m     run \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m   1177\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:785\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    783\u001b[0m         backend\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[1;32m--> 785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m run_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_result\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mCommError\u001b[0m: Run initialization has timed out after 90.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"NN-z1\"\n",
    "\n",
    "run = wandb.init(\n",
    "    entity = \"matus13579\",  #dont change\n",
    "    project = \"NN-z1\",      #dont change\n",
    "    name = \"relu_test\"       #run name\n",
    "    #id =                   #define run with ID (used for resuming)\n",
    "    #resume = True           #resume run\n",
    "    )\n",
    "\n",
    "#show graphs in Jupyter Notebook\n",
    "#%%wandb                   \n",
    "\n",
    "logger = logging.getLogger(\"wandb\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bioresponse.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset and Initialize NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_experiment(current_data):\n",
    "    # Split dataset -> 20% testing, 80% training\n",
    "    # Stratified split = each dataset has equal amounts of each class (saved in column 'target')\n",
    "    train, test = train_test_split(current_data, test_size = 0.2, stratify = current_data['target']) \n",
    "\n",
    "    # Initlize dataset for NN\n",
    "    train_data = CellDataset(train, False)\n",
    "    test_data = CellDataset(test, False)\n",
    "\n",
    "    # Create NN and training class\n",
    "    mlp = MultiLayerPerceptron(train_data.get_input_size())\n",
    "    trainer = Trainer(config, mlp)\n",
    "\n",
    "    # Load dataset\n",
    "    trainer.load_dataset(train_data, test_data)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(myrun, trainer: Trainer, no_epochs):\n",
    "    best_model = None\n",
    "    best_accuracy = None\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        # Train model\n",
    "        trainer.train()\n",
    "\n",
    "        # Get metrics\n",
    "        metrics = trainer.evaluate()\n",
    "\n",
    "        loss_tr, loss_val = trainer.mean_loss()\n",
    "        \n",
    "        print (f\"Epoch {epoch}\")\n",
    "        print (f\"loss_training: {loss_tr} | loss_validate: {loss_val}\")\n",
    "\n",
    "        myrun.log({\"loss_training\": loss_tr})\n",
    "        myrun.log({\"loss_validate\": loss_val})\n",
    "        myrun.log({\"accuracy\": metrics.accuracy})\n",
    "        myrun.log({\"f1_score\": metrics.accuracy})\n",
    "        \n",
    "        if (best_accuracy is None) or (best_accuracy > metrics.accuracy):\n",
    "            best_accuracy = metrics.accuracy\n",
    "            best_model = trainer.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = correlation_selection_merged(data)\n",
    "\n",
    "config.activation_fn = \"optimal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device for training\n",
      "Epoch 0\n",
      "loss_training: 9.517757415771484 | loss_validate: 9.505755424499512\n",
      "Epoch 1\n",
      "loss_training: 9.532607078552246 | loss_validate: 9.5322265625\n",
      "Epoch 2\n",
      "loss_training: 9.556146621704102 | loss_validate: 9.48403549194336\n",
      "Epoch 3\n",
      "loss_training: 9.536160469055176 | loss_validate: 9.522931098937988\n",
      "Epoch 4\n",
      "loss_training: 9.533585548400879 | loss_validate: 9.49963665008545\n",
      "Epoch 5\n",
      "loss_training: 9.496227264404297 | loss_validate: 9.517797470092773\n",
      "Epoch 6\n",
      "loss_training: 9.606687545776367 | loss_validate: 9.498635292053223\n",
      "Epoch 7\n",
      "loss_training: 9.499774932861328 | loss_validate: 9.525062561035156\n",
      "Epoch 8\n",
      "loss_training: 9.497215270996094 | loss_validate: 9.485235214233398\n",
      "Epoch 9\n",
      "loss_training: 9.5120267868042 | loss_validate: 9.519922256469727\n",
      "Epoch 10\n",
      "loss_training: 9.439984321594238 | loss_validate: 9.492541313171387\n",
      "Epoch 11\n",
      "loss_training: 9.454813957214355 | loss_validate: 9.498263359069824\n",
      "Epoch 12\n",
      "loss_training: 9.513028144836426 | loss_validate: 9.483285903930664\n",
      "Epoch 13\n",
      "loss_training: 9.46706771850586 | loss_validate: 9.509671211242676\n",
      "Epoch 14\n",
      "loss_training: 9.490540504455566 | loss_validate: 9.482300758361816\n",
      "Epoch 15\n",
      "loss_training: 9.470630645751953 | loss_validate: 9.500402450561523\n",
      "Epoch 16\n",
      "loss_training: 9.528765678405762 | loss_validate: 9.464773178100586\n",
      "Epoch 17\n",
      "loss_training: 9.482837677001953 | loss_validate: 9.491124153137207\n",
      "Epoch 18\n",
      "loss_training: 9.445609092712402 | loss_validate: 9.513337135314941\n",
      "Epoch 19\n",
      "loss_training: 9.486379623413086 | loss_validate: 9.506631851196289\n",
      "Epoch 20\n",
      "loss_training: 9.457826614379883 | loss_validate: 9.504063606262207\n",
      "Epoch 21\n",
      "loss_training: 9.472587585449219 | loss_validate: 9.493239402770996\n",
      "Epoch 22\n",
      "loss_training: 9.444052696228027 | loss_validate: 9.498923301696777\n",
      "Epoch 23\n",
      "loss_training: 9.450156211853027 | loss_validate: 9.471613883972168\n",
      "Epoch 24\n",
      "loss_training: 9.404342651367188 | loss_validate: 9.481430053710938\n",
      "Epoch 25\n",
      "loss_training: 9.410459518432617 | loss_validate: 9.445904731750488\n",
      "Epoch 26\n",
      "loss_training: 9.45980167388916 | loss_validate: 9.496903419494629\n",
      "Epoch 27\n",
      "loss_training: 9.47452449798584 | loss_validate: 9.42430305480957\n",
      "Epoch 28\n",
      "loss_training: 9.454665184020996 | loss_validate: 9.434098243713379\n",
      "Epoch 29\n",
      "loss_training: 9.400261878967285 | loss_validate: 9.427435874938965\n",
      "Epoch 30\n",
      "loss_training: 9.46682357788086 | loss_validate: 9.43310260772705\n",
      "Epoch 31\n",
      "loss_training: 9.48151969909668 | loss_validate: 9.471675872802734\n",
      "Epoch 32\n",
      "loss_training: 9.444404602050781 | loss_validate: 9.419744491577148\n",
      "Epoch 33\n",
      "loss_training: 9.484990119934082 | loss_validate: 9.41306209564209\n",
      "Epoch 34\n",
      "loss_training: 9.430632591247559 | loss_validate: 9.451615333557129\n",
      "Epoch 35\n",
      "loss_training: 9.428072929382324 | loss_validate: 9.416171073913574\n",
      "Epoch 36\n",
      "loss_training: 9.373771667480469 | loss_validate: 9.41773509979248\n",
      "Epoch 37\n",
      "loss_training: 9.448827743530273 | loss_validate: 9.415168762207031\n",
      "Epoch 38\n",
      "loss_training: 9.446252822875977 | loss_validate: 9.433135032653809\n",
      "Epoch 39\n",
      "loss_training: 9.452295303344727 | loss_validate: 9.446983337402344\n",
      "Epoch 40\n",
      "loss_training: 9.354962348937988 | loss_validate: 9.436222076416016\n",
      "Epoch 41\n",
      "loss_training: 9.386878967285156 | loss_validate: 9.400835990905762\n",
      "Epoch 42\n",
      "loss_training: 9.42737865447998 | loss_validate: 9.451600074768066\n",
      "Epoch 43\n",
      "loss_training: 9.442023277282715 | loss_validate: 9.412110328674316\n",
      "Epoch 44\n",
      "loss_training: 9.336188316345215 | loss_validate: 9.384967803955078\n",
      "Epoch 45\n",
      "loss_training: 9.38527774810791 | loss_validate: 9.394712448120117\n",
      "Epoch 46\n",
      "loss_training: 9.38272762298584 | loss_validate: 9.392158508300781\n",
      "Epoch 47\n",
      "loss_training: 9.431760787963867 | loss_validate: 9.373204231262207\n",
      "Epoch 48\n",
      "loss_training: 9.429181098937988 | loss_validate: 9.423879623413086\n",
      "Epoch 49\n",
      "loss_training: 9.392230033874512 | loss_validate: 9.392650604248047\n",
      "Epoch 50\n",
      "loss_training: 9.449803352355957 | loss_validate: 9.385979652404785\n",
      "Epoch 51\n",
      "loss_training: 9.430033683776855 | loss_validate: 9.350672721862793\n",
      "Epoch 52\n",
      "loss_training: 9.375933647155762 | loss_validate: 9.39721393585205\n",
      "Epoch 53\n",
      "loss_training: 9.399127960205078 | loss_validate: 9.423272132873535\n",
      "Epoch 54\n",
      "loss_training: 9.345071792602539 | loss_validate: 9.363468170166016\n",
      "Epoch 55\n",
      "loss_training: 9.419737815856934 | loss_validate: 9.397686958312988\n",
      "Epoch 56\n",
      "loss_training: 9.348543167114258 | loss_validate: 9.391040802001953\n",
      "Epoch 57\n",
      "loss_training: 9.397439956665039 | loss_validate: 9.368042945861816\n",
      "Epoch 58\n",
      "loss_training: 9.360578536987305 | loss_validate: 9.345063209533691\n",
      "Epoch 59\n",
      "loss_training: 9.409438133239746 | loss_validate: 9.375161170959473\n",
      "Epoch 60\n",
      "loss_training: 9.286916732788086 | loss_validate: 9.372618675231934\n",
      "Epoch 61\n",
      "loss_training: 9.387173652648926 | loss_validate: 9.365967750549316\n",
      "Epoch 62\n",
      "loss_training: 9.384597778320312 | loss_validate: 9.391956329345703\n",
      "Epoch 63\n",
      "loss_training: 9.356343269348145 | loss_validate: 9.381229400634766\n",
      "Epoch 64\n",
      "loss_training: 9.38801383972168 | loss_validate: 9.337876319885254\n",
      "Epoch 65\n",
      "loss_training: 9.334101676940918 | loss_validate: 9.38424015045166\n",
      "Epoch 66\n",
      "loss_training: 9.340103149414062 | loss_validate: 9.35314655303955\n",
      "Epoch 67\n",
      "loss_training: 9.363199234008789 | loss_validate: 9.330208778381348\n",
      "Epoch 68\n",
      "loss_training: 9.360629081726074 | loss_validate: 9.360230445861816\n",
      "Epoch 69\n",
      "loss_training: 9.35805892944336 | loss_validate: 9.361732482910156\n",
      "Epoch 70\n",
      "loss_training: 9.338400840759277 | loss_validate: 9.346953392028809\n",
      "Epoch 71\n",
      "loss_training: 9.318758010864258 | loss_validate: 9.352534294128418\n",
      "Epoch 72\n",
      "loss_training: 9.27351188659668 | loss_validate: 9.333710670471191\n",
      "Epoch 73\n",
      "loss_training: 9.305130004882812 | loss_validate: 9.32708740234375\n",
      "Epoch 74\n",
      "loss_training: 9.319652557373047 | loss_validate: 9.300132751464844\n",
      "Epoch 75\n",
      "loss_training: 9.4109468460083 | loss_validate: 9.317882537841797\n",
      "Epoch 76\n",
      "loss_training: 9.374220848083496 | loss_validate: 9.315308570861816\n",
      "Epoch 77\n",
      "loss_training: 9.346050262451172 | loss_validate: 9.333057403564453\n",
      "Epoch 78\n",
      "loss_training: 9.35200023651123 | loss_validate: 9.334545135498047\n",
      "Epoch 79\n",
      "loss_training: 9.392032623291016 | loss_validate: 9.315715789794922\n",
      "Epoch 80\n",
      "loss_training: 9.346829414367676 | loss_validate: 9.313145637512207\n",
      "Epoch 81\n",
      "loss_training: 9.327214241027832 | loss_validate: 9.3389892578125\n",
      "Epoch 82\n",
      "loss_training: 9.3246431350708 | loss_validate: 9.344529151916504\n",
      "Epoch 83\n",
      "loss_training: 9.322073936462402 | loss_validate: 9.386570930480957\n",
      "Epoch 84\n",
      "loss_training: 9.268439292907715 | loss_validate: 9.339390754699707\n",
      "Epoch 85\n",
      "loss_training: 9.308438301086426 | loss_validate: 9.308439254760742\n",
      "Epoch 86\n",
      "loss_training: 9.314379692077637 | loss_validate: 9.32613468170166\n",
      "Epoch 87\n",
      "loss_training: 9.26928997039795 | loss_validate: 9.315470695495605\n",
      "Epoch 88\n",
      "loss_training: 9.2582426071167 | loss_validate: 9.296709060668945\n",
      "Epoch 89\n",
      "loss_training: 9.298195838928223 | loss_validate: 9.302244186401367\n",
      "Epoch 90\n",
      "loss_training: 9.270139694213867 | loss_validate: 9.291587829589844\n",
      "Epoch 91\n",
      "loss_training: 9.301566123962402 | loss_validate: 9.325446128845215\n",
      "Epoch 92\n",
      "loss_training: 9.298995018005371 | loss_validate: 9.302638053894043\n",
      "Epoch 93\n",
      "loss_training: 9.262467384338379 | loss_validate: 9.30007553100586\n",
      "Epoch 94\n",
      "loss_training: 9.268403053283691 | loss_validate: 9.29346752166748\n",
      "Epoch 95\n",
      "loss_training: 9.299786567687988 | loss_validate: 9.290894508361816\n",
      "Epoch 96\n",
      "loss_training: 9.271763801574707 | loss_validate: 9.320661544799805\n",
      "Epoch 97\n",
      "loss_training: 9.337044715881348 | loss_validate: 9.285743713378906\n",
      "Epoch 98\n",
      "loss_training: 9.20727825164795 | loss_validate: 9.254918098449707\n",
      "Epoch 99\n",
      "loss_training: 9.221701622009277 | loss_validate: 9.300832748413086\n",
      "Epoch 100\n",
      "loss_training: 9.22763729095459 | loss_validate: 9.310381889343262\n",
      "Epoch 101\n",
      "loss_training: 9.258977890014648 | loss_validate: 9.247265815734863\n",
      "Epoch 102\n",
      "loss_training: 9.239480018615723 | loss_validate: 9.244711875915527\n",
      "Epoch 103\n",
      "loss_training: 9.262327194213867 | loss_validate: 9.254253387451172\n",
      "Epoch 104\n",
      "loss_training: 9.225907325744629 | loss_validate: 9.239601135253906\n",
      "Epoch 105\n",
      "loss_training: 9.240283012390137 | loss_validate: 9.249139785766602\n",
      "Epoch 106\n",
      "loss_training: 9.212348937988281 | loss_validate: 9.242557525634766\n",
      "Epoch 107\n",
      "loss_training: 9.285919189453125 | loss_validate: 9.223868370056152\n",
      "Epoch 108\n",
      "loss_training: 9.249516487121582 | loss_validate: 9.233394622802734\n",
      "Epoch 109\n",
      "loss_training: 9.230046272277832 | loss_validate: 9.234865188598633\n",
      "Epoch 110\n",
      "loss_training: 9.219039916992188 | loss_validate: 9.264519691467285\n",
      "Epoch 111\n",
      "loss_training: 9.199593544006348 | loss_validate: 9.249884605407715\n",
      "Epoch 112\n",
      "loss_training: 9.247722625732422 | loss_validate: 9.255361557006836\n",
      "Epoch 113\n",
      "loss_training: 9.253596305847168 | loss_validate: 9.268877983093262\n",
      "Epoch 114\n",
      "loss_training: 9.284781455993652 | loss_validate: 9.254223823547363\n",
      "Epoch 115\n",
      "loss_training: 9.256874084472656 | loss_validate: 9.235564231872559\n",
      "Epoch 116\n",
      "loss_training: 9.203680992126465 | loss_validate: 9.216925621032715\n",
      "Epoch 117\n",
      "loss_training: 9.234862327575684 | loss_validate: 9.226415634155273\n",
      "Epoch 118\n",
      "loss_training: 9.206999778747559 | loss_validate: 9.231888771057129\n",
      "Epoch 119\n",
      "loss_training: 9.212872505187988 | loss_validate: 9.233339309692383\n",
      "Epoch 120\n",
      "loss_training: 9.193459510803223 | loss_validate: 9.24282169342041\n",
      "Epoch 121\n",
      "loss_training: 9.224601745605469 | loss_validate: 9.1920804977417\n",
      "Epoch 122\n",
      "loss_training: 9.238876342773438 | loss_validate: 9.253718376159668\n",
      "Epoch 123\n",
      "loss_training: 9.219457626342773 | loss_validate: 9.223057746887207\n",
      "Epoch 124\n",
      "loss_training: 9.242138862609863 | loss_validate: 9.192405700683594\n",
      "Epoch 125\n",
      "loss_training: 9.189065933227539 | loss_validate: 9.209895133972168\n",
      "Epoch 126\n",
      "loss_training: 9.186511039733887 | loss_validate: 9.223365783691406\n",
      "Epoch 127\n",
      "loss_training: 9.200774192810059 | loss_validate: 9.240830421447754\n",
      "Epoch 128\n",
      "loss_training: 9.181392669677734 | loss_validate: 9.206210136413574\n",
      "Epoch 129\n",
      "loss_training: 9.153620719909668 | loss_validate: 9.207657814025879\n",
      "Epoch 130\n",
      "loss_training: 9.201496124267578 | loss_validate: 9.173056602478027\n",
      "Epoch 131\n",
      "loss_training: 9.173725128173828 | loss_validate: 9.198519706726074\n",
      "Epoch 132\n",
      "loss_training: 9.221558570861816 | loss_validate: 9.1719331741333\n",
      "Epoch 133\n",
      "loss_training: 9.160202026367188 | loss_validate: 9.189380645751953\n",
      "Epoch 134\n",
      "loss_training: 9.166045188903809 | loss_validate: 9.194816589355469\n",
      "Epoch 135\n",
      "loss_training: 9.155097961425781 | loss_validate: 9.176261901855469\n",
      "Epoch 136\n",
      "loss_training: 9.202878952026367 | loss_validate: 9.181684494018555\n",
      "Epoch 137\n",
      "loss_training: 9.158367156982422 | loss_validate: 9.163138389587402\n",
      "Epoch 138\n",
      "loss_training: 9.147427558898926 | loss_validate: 9.152592658996582\n",
      "Epoch 139\n",
      "loss_training: 9.211930274963379 | loss_validate: 9.177976608276367\n",
      "Epoch 140\n",
      "loss_training: 9.142304420471191 | loss_validate: 9.135490417480469\n",
      "Epoch 141\n",
      "loss_training: 9.139752388000488 | loss_validate: 9.17285442352295\n",
      "Epoch 142\n",
      "loss_training: 9.162327766418457 | loss_validate: 9.198219299316406\n",
      "Epoch 143\n",
      "loss_training: 9.20162296295166 | loss_validate: 9.127814292907715\n",
      "Epoch 144\n",
      "loss_training: 9.140442848205566 | loss_validate: 9.153179168701172\n",
      "Epoch 145\n",
      "loss_training: 9.154623985290527 | loss_validate: 9.122705459594727\n",
      "Epoch 146\n",
      "loss_training: 9.160423278808594 | loss_validate: 9.167977333068848\n",
      "Epoch 147\n",
      "loss_training: 9.090949058532715 | loss_validate: 9.165421485900879\n",
      "Epoch 148\n",
      "loss_training: 9.08841609954834 | loss_validate: 9.13498306274414\n",
      "Epoch 149\n",
      "loss_training: 9.110957145690918 | loss_validate: 9.112517356872559\n",
      "Epoch 150\n",
      "loss_training: 9.14183521270752 | loss_validate: 9.125885963439941\n",
      "Epoch 151\n",
      "loss_training: 9.072440147399902 | loss_validate: 9.15518569946289\n",
      "Epoch 152\n",
      "loss_training: 9.094965934753418 | loss_validate: 9.124772071838379\n",
      "Epoch 153\n",
      "loss_training: 9.12582015991211 | loss_validate: 9.138124465942383\n",
      "Epoch 154\n",
      "loss_training: 9.131606101989746 | loss_validate: 9.111696243286133\n",
      "Epoch 155\n",
      "loss_training: 9.129040718078613 | loss_validate: 9.16877269744873\n",
      "Epoch 156\n",
      "loss_training: 9.118133544921875 | loss_validate: 9.14632511138916\n",
      "Epoch 157\n",
      "loss_training: 9.148929595947266 | loss_validate: 9.107983589172363\n",
      "Epoch 158\n",
      "loss_training: 9.10466480255127 | loss_validate: 9.121317863464355\n",
      "Epoch 159\n",
      "loss_training: 9.127113342285156 | loss_validate: 9.122720718383789\n",
      "Epoch 160\n",
      "loss_training: 9.107878684997559 | loss_validate: 9.143978118896484\n",
      "Epoch 161\n",
      "loss_training: 9.047004699707031 | loss_validate: 9.10966968536377\n",
      "Epoch 162\n",
      "loss_training: 9.10277271270752 | loss_validate: 9.122979164123535\n",
      "Epoch 163\n",
      "loss_training: 9.150165557861328 | loss_validate: 9.088663101196289\n",
      "Epoch 164\n",
      "loss_training: 9.130928993225098 | loss_validate: 9.078164100646973\n",
      "Epoch 165\n",
      "loss_training: 9.111708641052246 | loss_validate: 9.099390983581543\n",
      "Epoch 166\n",
      "loss_training: 9.050909042358398 | loss_validate: 9.080986976623535\n",
      "Epoch 167\n",
      "loss_training: 9.056687355041504 | loss_validate: 9.09428882598877\n",
      "Epoch 168\n",
      "loss_training: 9.10402774810791 | loss_validate: 9.087759971618652\n",
      "Epoch 169\n",
      "loss_training: 9.093146324157715 | loss_validate: 9.116877555847168\n",
      "Epoch 170\n",
      "loss_training: 9.08227252960205 | loss_validate: 9.070756912231445\n",
      "Epoch 171\n",
      "loss_training: 9.11293888092041 | loss_validate: 9.091938018798828\n",
      "Epoch 172\n",
      "loss_training: 9.102054595947266 | loss_validate: 9.128934860229492\n",
      "Epoch 173\n",
      "loss_training: 9.099479675292969 | loss_validate: 9.082839012145996\n",
      "Epoch 174\n",
      "loss_training: 9.113505363464355 | loss_validate: 9.103991508483887\n",
      "Epoch 175\n",
      "loss_training: 9.036242485046387 | loss_validate: 9.089570045471191\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m current_trainer \u001b[38;5;241m=\u001b[39m setup_experiment(current_data)\n\u001b[1;32m----> 2\u001b[0m run_experiment(run, current_trainer, \u001b[38;5;241m1000\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(myrun, trainer, no_epochs)\u001b[0m\n\u001b[0;32m      3\u001b[0m best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(no_epochs):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Get metrics\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22196\\4200513415.py:41\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, logger)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_train \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Train model on each dataset batch (train_data)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data):\n\u001b[0;32m     42\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Forward Pass - prediction and its error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[38;5;241m=\u001b[39mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\matul\\anaconda3\\envs\\NN\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:183\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([torch\u001b[38;5;241m.\u001b[39mas_tensor(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "current_trainer = setup_experiment(current_data)\n",
    "run_experiment(run, current_trainer, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
